INFO:train_ppo_vecnorm:Creando 8 entornos paralelos con VecNormalize...
INFO:train_ppo_vecnorm:Activando wrapper de reparacion de acciones invalidas durante TRAINING...
INFO:train_ppo_vecnorm:Aplicando VecNormalize (obs y reward normalizados)...
INFO:train_ppo_vecnorm:Entrenando PPO Fase 1 por 400000 timesteps...
Argumentos de entrenamiento:
  timesteps: 400000
  timesteps2: 400000
  timesteps3: 300000
  n_envs: 8
  seed: 42
  lr: 0.0003
  n_steps: 2048
  batch_size: 64
  n_epochs: 8
  gamma: 0.99
  gae_lambda: 0.95
  ent_coef: 0.02
  clip_range: 0.1
  vf_coef: 0.5
  max_grad_norm: 0.5
  target_kl: 0.02
  use_sde: False
  sde_sample_freq: -1
  policy_arch: {"pi":[256, 256], "vf":[256, 256]}
  eval_episodes: 50
  best_dir: best/ppo_ablation/ppo_conservative_clip_kl/seed_42/best
  plot_ma_long: 200
  repair_actions_training: True
Using cpu device
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 33.3     |
|    ep_rew_mean     | 78.9     |
| time/              |          |
|    fps             | 1705     |
|    iterations      | 1        |
|    time_elapsed    | 9        |
|    total_timesteps | 16384    |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 33.5        |
|    ep_rew_mean          | 82.2        |
| time/                   |             |
|    fps                  | 983         |
|    iterations           | 2           |
|    time_elapsed         | 33          |
|    total_timesteps      | 32768       |
| train/                  |             |
|    approx_kl            | 0.006949596 |
|    clip_fraction        | 0.279       |
|    clip_range           | 0.1         |
|    entropy_loss         | -3.78       |
|    explained_variance   | -0.228      |
|    learning_rate        | 0.0003      |
|    loss                 | 0.0473      |
|    n_updates            | 8           |
|    policy_gradient_loss | -0.00901    |
|    value_loss           | 0.289       |
-----------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 33.7         |
|    ep_rew_mean          | 82.8         |
| time/                   |              |
|    fps                  | 868          |
|    iterations           | 3            |
|    time_elapsed         | 56           |
|    total_timesteps      | 49152        |
| train/                  |              |
|    approx_kl            | 0.0050530527 |
|    clip_fraction        | 0.288        |
|    clip_range           | 0.1          |
|    entropy_loss         | -3.77        |
|    explained_variance   | 0.717        |
|    learning_rate        | 0.0003       |
|    loss                 | 0.000198     |
|    n_updates            | 16           |
|    policy_gradient_loss | -0.0087      |
|    value_loss           | 0.173        |
------------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 34          |
|    ep_rew_mean          | 83.9        |
| time/                   |             |
|    fps                  | 815         |
|    iterations           | 4           |
|    time_elapsed         | 80          |
|    total_timesteps      | 65536       |
| train/                  |             |
|    approx_kl            | 0.005132518 |
|    clip_fraction        | 0.288       |
|    clip_range           | 0.1         |
|    entropy_loss         | -3.77       |
|    explained_variance   | 0.76        |
|    learning_rate        | 0.0003      |
|    loss                 | 0.0306      |
|    n_updates            | 24          |
|    policy_gradient_loss | -0.0095     |
|    value_loss           | 0.168       |
-----------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 34.3         |
|    ep_rew_mean          | 83.6         |
| time/                   |              |
|    fps                  | 791          |
|    iterations           | 5            |
|    time_elapsed         | 103          |
|    total_timesteps      | 81920        |
| train/                  |              |
|    approx_kl            | 0.0055901487 |
|    clip_fraction        | 0.303        |
|    clip_range           | 0.1          |
|    entropy_loss         | -3.76        |
|    explained_variance   | 0.796        |
|    learning_rate        | 0.0003       |
|    loss                 | 0.0332       |
|    n_updates            | 32           |
|    policy_gradient_loss | -0.0109      |
|    value_loss           | 0.166        |
------------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 34.3         |
|    ep_rew_mean          | 91.8         |
| time/                   |              |
|    fps                  | 769          |
|    iterations           | 6            |
|    time_elapsed         | 127          |
|    total_timesteps      | 98304        |
| train/                  |              |
|    approx_kl            | 0.0053867693 |
|    clip_fraction        | 0.306        |
|    clip_range           | 0.1          |
|    entropy_loss         | -3.75        |
|    explained_variance   | 0.805        |
|    learning_rate        | 0.0003       |
|    loss                 | 0.000674     |
|    n_updates            | 40           |
|    policy_gradient_loss | -0.0109      |
|    value_loss           | 0.17         |
------------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 35.2        |
|    ep_rew_mean          | 91.2        |
| time/                   |             |
|    fps                  | 756         |
|    iterations           | 7           |
|    time_elapsed         | 151         |
|    total_timesteps      | 114688      |
| train/                  |             |
|    approx_kl            | 0.005595507 |
|    clip_fraction        | 0.319       |
|    clip_range           | 0.1         |
|    entropy_loss         | -3.74       |
|    explained_variance   | 0.82        |
|    learning_rate        | 0.0003      |
|    loss                 | -0.0433     |
|    n_updates            | 48          |
|    policy_gradient_loss | -0.0111     |
|    value_loss           | 0.151       |
-----------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 35.1         |
|    ep_rew_mean          | 91.6         |
| time/                   |              |
|    fps                  | 749          |
|    iterations           | 8            |
|    time_elapsed         | 174          |
|    total_timesteps      | 131072       |
| train/                  |              |
|    approx_kl            | 0.0056245895 |
|    clip_fraction        | 0.309        |
|    clip_range           | 0.1          |
|    entropy_loss         | -3.73        |
|    explained_variance   | 0.816        |
|    learning_rate        | 0.0003       |
|    loss                 | -0.015       |
|    n_updates            | 56           |
|    policy_gradient_loss | -0.0109      |
|    value_loss           | 0.155        |
------------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 35.3         |
|    ep_rew_mean          | 92.6         |
| time/                   |              |
|    fps                  | 718          |
|    iterations           | 9            |
|    time_elapsed         | 205          |
|    total_timesteps      | 147456       |
| train/                  |              |
|    approx_kl            | 0.0059930864 |
|    clip_fraction        | 0.326        |
|    clip_range           | 0.1          |
|    entropy_loss         | -3.72        |
|    explained_variance   | 0.799        |
|    learning_rate        | 0.0003       |
|    loss                 | -0.00689     |
|    n_updates            | 64           |
|    policy_gradient_loss | -0.0126      |
|    value_loss           | 0.161        |
------------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 35.1         |
|    ep_rew_mean          | 98.1         |
| time/                   |              |
|    fps                  | 697          |
|    iterations           | 10           |
|    time_elapsed         | 235          |
|    total_timesteps      | 163840       |
| train/                  |              |
|    approx_kl            | 0.0061345063 |
|    clip_fraction        | 0.336        |
|    clip_range           | 0.1          |
|    entropy_loss         | -3.71        |
|    explained_variance   | 0.813        |
|    learning_rate        | 0.0003       |
|    loss                 | -0.0181      |
|    n_updates            | 72           |
|    policy_gradient_loss | -0.0128      |
|    value_loss           | 0.161        |
------------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 35.4         |
|    ep_rew_mean          | 92.6         |
| time/                   |              |
|    fps                  | 688          |
|    iterations           | 11           |
|    time_elapsed         | 261          |
|    total_timesteps      | 180224       |
| train/                  |              |
|    approx_kl            | 0.0061187875 |
|    clip_fraction        | 0.33         |
|    clip_range           | 0.1          |
|    entropy_loss         | -3.7         |
|    explained_variance   | 0.814        |
|    learning_rate        | 0.0003       |
|    loss                 | -0.0473      |
|    n_updates            | 80           |
|    policy_gradient_loss | -0.0125      |
|    value_loss           | 0.159        |
------------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 35.4         |
|    ep_rew_mean          | 91.9         |
| time/                   |              |
|    fps                  | 685          |
|    iterations           | 12           |
|    time_elapsed         | 286          |
|    total_timesteps      | 196608       |
| train/                  |              |
|    approx_kl            | 0.0067273886 |
|    clip_fraction        | 0.346        |
|    clip_range           | 0.1          |
|    entropy_loss         | -3.69        |
|    explained_variance   | 0.817        |
|    learning_rate        | 0.0003       |
|    loss                 | -0.0181      |
|    n_updates            | 88           |
|    policy_gradient_loss | -0.0139      |
|    value_loss           | 0.152        |
------------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 35.8         |
|    ep_rew_mean          | 97.1         |
| time/                   |              |
|    fps                  | 684          |
|    iterations           | 13           |
|    time_elapsed         | 311          |
|    total_timesteps      | 212992       |
| train/                  |              |
|    approx_kl            | 0.0067738127 |
|    clip_fraction        | 0.348        |
|    clip_range           | 0.1          |
|    entropy_loss         | -3.69        |
|    explained_variance   | 0.807        |
|    learning_rate        | 0.0003       |
|    loss                 | -0.0216      |
|    n_updates            | 96           |
|    policy_gradient_loss | -0.014       |
|    value_loss           | 0.156        |
------------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 36.2         |
|    ep_rew_mean          | 99.4         |
| time/                   |              |
|    fps                  | 682          |
|    iterations           | 14           |
|    time_elapsed         | 336          |
|    total_timesteps      | 229376       |
| train/                  |              |
|    approx_kl            | 0.0073027015 |
|    clip_fraction        | 0.354        |
|    clip_range           | 0.1          |
|    entropy_loss         | -3.68        |
|    explained_variance   | 0.825        |
|    learning_rate        | 0.0003       |
|    loss                 | 0.0259       |
|    n_updates            | 104          |
|    policy_gradient_loss | -0.0142      |
|    value_loss           | 0.151        |
------------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 36.3        |
|    ep_rew_mean          | 101         |
| time/                   |             |
|    fps                  | 678         |
|    iterations           | 15          |
|    time_elapsed         | 362         |
|    total_timesteps      | 245760      |
| train/                  |             |
|    approx_kl            | 0.007847788 |
|    clip_fraction        | 0.364       |
|    clip_range           | 0.1         |
|    entropy_loss         | -3.67       |
|    explained_variance   | 0.83        |
|    learning_rate        | 0.0003      |
|    loss                 | -0.0165     |
|    n_updates            | 112         |
|    policy_gradient_loss | -0.0152     |
|    value_loss           | 0.146       |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 36.2        |
|    ep_rew_mean          | 96.2        |
| time/                   |             |
|    fps                  | 677         |
|    iterations           | 16          |
|    time_elapsed         | 387         |
|    total_timesteps      | 262144      |
| train/                  |             |
|    approx_kl            | 0.007820562 |
|    clip_fraction        | 0.374       |
|    clip_range           | 0.1         |
|    entropy_loss         | -3.66       |
|    explained_variance   | 0.816       |
|    learning_rate        | 0.0003      |
|    loss                 | -0.0121     |
|    n_updates            | 120         |
|    policy_gradient_loss | -0.0162     |
|    value_loss           | 0.157       |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 36.1       |
|    ep_rew_mean          | 93.7       |
| time/                   |            |
|    fps                  | 675        |
|    iterations           | 17         |
|    time_elapsed         | 412        |
|    total_timesteps      | 278528     |
| train/                  |            |
|    approx_kl            | 0.00798882 |
|    clip_fraction        | 0.373      |
|    clip_range           | 0.1        |
|    entropy_loss         | -3.65      |
|    explained_variance   | 0.807      |
|    learning_rate        | 0.0003     |
|    loss                 | -0.0346    |
|    n_updates            | 128        |
|    policy_gradient_loss | -0.0152    |
|    value_loss           | 0.167      |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 36.3        |
|    ep_rew_mean          | 104         |
| time/                   |             |
|    fps                  | 674         |
|    iterations           | 18          |
|    time_elapsed         | 436         |
|    total_timesteps      | 294912      |
| train/                  |             |
|    approx_kl            | 0.008392537 |
|    clip_fraction        | 0.388       |
|    clip_range           | 0.1         |
|    entropy_loss         | -3.64       |
|    explained_variance   | 0.821       |
|    learning_rate        | 0.0003      |
|    loss                 | -0.0219     |
|    n_updates            | 136         |
|    policy_gradient_loss | -0.0164     |
|    value_loss           | 0.147       |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 36.8        |
|    ep_rew_mean          | 102         |
| time/                   |             |
|    fps                  | 671         |
|    iterations           | 19          |
|    time_elapsed         | 463         |
|    total_timesteps      | 311296      |
| train/                  |             |
|    approx_kl            | 0.008573747 |
|    clip_fraction        | 0.389       |
|    clip_range           | 0.1         |
|    entropy_loss         | -3.63       |
|    explained_variance   | 0.828       |
|    learning_rate        | 0.0003      |
|    loss                 | -0.0555     |
|    n_updates            | 144         |
|    policy_gradient_loss | -0.0168     |
|    value_loss           | 0.131       |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 36.7        |
|    ep_rew_mean          | 102         |
| time/                   |             |
|    fps                  | 669         |
|    iterations           | 20          |
|    time_elapsed         | 489         |
|    total_timesteps      | 327680      |
| train/                  |             |
|    approx_kl            | 0.008909764 |
|    clip_fraction        | 0.399       |
|    clip_range           | 0.1         |
|    entropy_loss         | -3.62       |
|    explained_variance   | 0.822       |
|    learning_rate        | 0.0003      |
|    loss                 | -0.0246     |
|    n_updates            | 152         |
|    policy_gradient_loss | -0.017      |
|    value_loss           | 0.147       |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 36.8        |
|    ep_rew_mean          | 109         |
| time/                   |             |
|    fps                  | 668         |
|    iterations           | 21          |
|    time_elapsed         | 514         |
|    total_timesteps      | 344064      |
| train/                  |             |
|    approx_kl            | 0.009846774 |
|    clip_fraction        | 0.416       |
|    clip_range           | 0.1         |
|    entropy_loss         | -3.61       |
|    explained_variance   | 0.835       |
|    learning_rate        | 0.0003      |
|    loss                 | -0.0287     |
|    n_updates            | 160         |
|    policy_gradient_loss | -0.0181     |
|    value_loss           | 0.139       |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 36.9        |
|    ep_rew_mean          | 106         |
| time/                   |             |
|    fps                  | 669         |
|    iterations           | 22          |
|    time_elapsed         | 538         |
|    total_timesteps      | 360448      |
| train/                  |             |
|    approx_kl            | 0.009539131 |
|    clip_fraction        | 0.41        |
|    clip_range           | 0.1         |
|    entropy_loss         | -3.6        |
|    explained_variance   | 0.834       |
|    learning_rate        | 0.0003      |
|    loss                 | -0.033      |
|    n_updates            | 168         |
|    policy_gradient_loss | -0.0182     |
|    value_loss           | 0.137       |
-----------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 37        |
|    ep_rew_mean          | 102       |
| time/                   |           |
|    fps                  | 666       |
|    iterations           | 23        |
|    time_elapsed         | 565       |
|    total_timesteps      | 376832    |
| train/                  |           |
|    approx_kl            | 0.0096025 |
|    clip_fraction        | 0.41      |
|    clip_range           | 0.1       |
|    entropy_loss         | -3.59     |
|    explained_variance   | 0.835     |
|    learning_rate        | 0.0003    |
|    loss                 | -0.0422   |
|    n_updates            | 176       |
|    policy_gradient_loss | -0.0172   |
|    value_loss           | 0.135     |
---------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 37          |
|    ep_rew_mean          | 104         |
| time/                   |             |
|    fps                  | 665         |
|    iterations           | 24          |
|    time_elapsed         | 591         |
|    total_timesteps      | 393216      |
| train/                  |             |
|    approx_kl            | 0.009821511 |
|    clip_fraction        | 0.418       |
|    clip_range           | 0.1         |
|    entropy_loss         | -3.58       |
|    explained_variance   | 0.833       |
|    learning_rate        | 0.0003      |
|    loss                 | -0.0375     |
|    n_updates            | 184         |
|    policy_gradient_loss | -0.0179     |
|    value_loss           | 0.138       |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 37.1        |
|    ep_rew_mean          | 102         |
| time/                   |             |
|    fps                  | 666         |
|    iterations           | 25          |
|    time_elapsed         | 614         |
|    total_timesteps      | 409600      |
| train/                  |             |
|    approx_kl            | 0.010239448 |
|    clip_fraction        | 0.428       |
|    clip_range           | 0.1         |
|    entropy_loss         | -3.57       |
|    explained_variance   | 0.837       |
|    learning_rate        | 0.0003      |
|    loss                 | -0.0482     |
|    n_updates            | 192         |
|    policy_gradient_loss | -0.0179     |
|    value_loss           | 0.13        |
-----------------------------------------
INFO:train_ppo_vecnorm:Entrenando PPO Fase 2 por 400000 timesteps...
Using cpu device
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 37.2     |
|    ep_rew_mean     | 104      |
| time/              |          |
|    fps             | 1739     |
|    iterations      | 1        |
|    time_elapsed    | 18       |
|    total_timesteps | 32768    |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 37.1        |
|    ep_rew_mean          | 102         |
| time/                   |             |
|    fps                  | 938         |
|    iterations           | 2           |
|    time_elapsed         | 69          |
|    total_timesteps      | 65536       |
| train/                  |             |
|    approx_kl            | 0.010403062 |
|    clip_fraction        | 0.426       |
|    clip_range           | 0.1         |
|    entropy_loss         | -3.56       |
|    explained_variance   | 0.832       |
|    learning_rate        | 0.0003      |
|    loss                 | -0.00575    |
|    n_updates            | 8           |
|    policy_gradient_loss | -0.0105     |
|    value_loss           | 0.145       |
-----------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 37.1         |
|    ep_rew_mean          | 108          |
| time/                   |              |
|    fps                  | 815          |
|    iterations           | 3            |
|    time_elapsed         | 120          |
|    total_timesteps      | 98304        |
| train/                  |              |
|    approx_kl            | 0.0111597525 |
|    clip_fraction        | 0.438        |
|    clip_range           | 0.1          |
|    entropy_loss         | -3.55        |
|    explained_variance   | 0.845        |
|    learning_rate        | 0.0003       |
|    loss                 | 0.0246       |
|    n_updates            | 16           |
|    policy_gradient_loss | -0.0116      |
|    value_loss           | 0.135        |
------------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 37.5        |
|    ep_rew_mean          | 104         |
| time/                   |             |
|    fps                  | 753         |
|    iterations           | 4           |
|    time_elapsed         | 173         |
|    total_timesteps      | 131072      |
| train/                  |             |
|    approx_kl            | 0.011587383 |
|    clip_fraction        | 0.441       |
|    clip_range           | 0.1         |
|    entropy_loss         | -3.54       |
|    explained_variance   | 0.832       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.0409      |
|    n_updates            | 24          |
|    policy_gradient_loss | -0.0112     |
|    value_loss           | 0.148       |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 37.4        |
|    ep_rew_mean          | 107         |
| time/                   |             |
|    fps                  | 713         |
|    iterations           | 5           |
|    time_elapsed         | 229         |
|    total_timesteps      | 163840      |
| train/                  |             |
|    approx_kl            | 0.011782357 |
|    clip_fraction        | 0.444       |
|    clip_range           | 0.1         |
|    entropy_loss         | -3.52       |
|    explained_variance   | 0.827       |
|    learning_rate        | 0.0003      |
|    loss                 | -0.00421    |
|    n_updates            | 32          |
|    policy_gradient_loss | -0.0116     |
|    value_loss           | 0.154       |
-----------------------------------------
Early stopping at step 7 due to reaching max kl: 0.04
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 37.6        |
|    ep_rew_mean          | 105         |
| time/                   |             |
|    fps                  | 604         |
|    iterations           | 6           |
|    time_elapsed         | 325         |
|    total_timesteps      | 196608      |
| train/                  |             |
|    approx_kl            | 0.012097724 |
|    clip_fraction        | 0.453       |
|    clip_range           | 0.1         |
|    entropy_loss         | -3.51       |
|    explained_variance   | 0.84        |
|    learning_rate        | 0.0003      |
|    loss                 | 0.000622    |
|    n_updates            | 40          |
|    policy_gradient_loss | -0.0121     |
|    value_loss           | 0.14        |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 37.5       |
|    ep_rew_mean          | 105        |
| time/                   |            |
|    fps                  | 593        |
|    iterations           | 7          |
|    time_elapsed         | 386        |
|    total_timesteps      | 229376     |
| train/                  |            |
|    approx_kl            | 0.01266258 |
|    clip_fraction        | 0.461      |
|    clip_range           | 0.1        |
|    entropy_loss         | -3.5       |
|    explained_variance   | 0.848      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.00772    |
|    n_updates            | 48         |
|    policy_gradient_loss | -0.0127    |
|    value_loss           | 0.14       |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 37.4        |
|    ep_rew_mean          | 106         |
| time/                   |             |
|    fps                  | 590         |
|    iterations           | 8           |
|    time_elapsed         | 444         |
|    total_timesteps      | 262144      |
| train/                  |             |
|    approx_kl            | 0.012453941 |
|    clip_fraction        | 0.46        |
|    clip_range           | 0.1         |
|    entropy_loss         | -3.49       |
|    explained_variance   | 0.84        |
|    learning_rate        | 0.0003      |
|    loss                 | -0.0125     |
|    n_updates            | 56          |
|    policy_gradient_loss | -0.0121     |
|    value_loss           | 0.141       |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 37.6        |
|    ep_rew_mean          | 107         |
| time/                   |             |
|    fps                  | 586         |
|    iterations           | 9           |
|    time_elapsed         | 502         |
|    total_timesteps      | 294912      |
| train/                  |             |
|    approx_kl            | 0.012773086 |
|    clip_fraction        | 0.462       |
|    clip_range           | 0.1         |
|    entropy_loss         | -3.48       |
|    explained_variance   | 0.837       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.0423      |
|    n_updates            | 64          |
|    policy_gradient_loss | -0.0129     |
|    value_loss           | 0.142       |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 37.5        |
|    ep_rew_mean          | 107         |
| time/                   |             |
|    fps                  | 579         |
|    iterations           | 10          |
|    time_elapsed         | 565         |
|    total_timesteps      | 327680      |
| train/                  |             |
|    approx_kl            | 0.013031445 |
|    clip_fraction        | 0.469       |
|    clip_range           | 0.1         |
|    entropy_loss         | -3.47       |
|    explained_variance   | 0.846       |
|    learning_rate        | 0.0003      |
|    loss                 | 2.76e-05    |
|    n_updates            | 72          |
|    policy_gradient_loss | -0.0126     |
|    value_loss           | 0.136       |
-----------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 37.9         |
|    ep_rew_mean          | 109          |
| time/                   |              |
|    fps                  | 580          |
|    iterations           | 11           |
|    time_elapsed         | 620          |
|    total_timesteps      | 360448       |
| train/                  |              |
|    approx_kl            | 0.0136817545 |
|    clip_fraction        | 0.478        |
|    clip_range           | 0.1          |
|    entropy_loss         | -3.46        |
|    explained_variance   | 0.857        |
|    learning_rate        | 0.0003       |
|    loss                 | 0.045        |
|    n_updates            | 80           |
|    policy_gradient_loss | -0.0123      |
|    value_loss           | 0.13         |
------------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 37.6        |
|    ep_rew_mean          | 106         |
| time/                   |             |
|    fps                  | 582         |
|    iterations           | 12          |
|    time_elapsed         | 675         |
|    total_timesteps      | 393216      |
| train/                  |             |
|    approx_kl            | 0.014070947 |
|    clip_fraction        | 0.485       |
|    clip_range           | 0.1         |
|    entropy_loss         | -3.45       |
|    explained_variance   | 0.857       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.0268      |
|    n_updates            | 88          |
|    policy_gradient_loss | -0.0133     |
|    value_loss           | 0.129       |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 37.7        |
|    ep_rew_mean          | 108         |
| time/                   |             |
|    fps                  | 583         |
|    iterations           | 13          |
|    time_elapsed         | 730         |
|    total_timesteps      | 425984      |
| train/                  |             |
|    approx_kl            | 0.014510453 |
|    clip_fraction        | 0.486       |
|    clip_range           | 0.1         |
|    entropy_loss         | -3.43       |
|    explained_variance   | 0.847       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.0057      |
|    n_updates            | 96          |
|    policy_gradient_loss | -0.0136     |
|    value_loss           | 0.127       |
-----------------------------------------
INFO:train_ppo_vecnorm:Entrenando PPO Fase 3 por 300000 timesteps...
Using cpu device
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 37.8     |
|    ep_rew_mean     | 110      |
| time/              |          |
|    fps             | 1558     |
|    iterations      | 1        |
|    time_elapsed    | 31       |
|    total_timesteps | 49152    |
---------------------------------
Early stopping at step 7 due to reaching max kl: 0.03
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 38          |
|    ep_rew_mean          | 111         |
| time/                   |             |
|    fps                  | 698         |
|    iterations           | 2           |
|    time_elapsed         | 140         |
|    total_timesteps      | 98304       |
| train/                  |             |
|    approx_kl            | 0.014541412 |
|    clip_fraction        | 0.489       |
|    clip_range           | 0.1         |
|    entropy_loss         | -3.42       |
|    explained_variance   | 0.849       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.0435      |
|    n_updates            | 8           |
|    policy_gradient_loss | -0.00845    |
|    value_loss           | 0.133       |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 37.8        |
|    ep_rew_mean          | 109         |
| time/                   |             |
|    fps                  | 509         |
|    iterations           | 3           |
|    time_elapsed         | 289         |
|    total_timesteps      | 147456      |
| train/                  |             |
|    approx_kl            | 0.014733766 |
|    clip_fraction        | 0.498       |
|    clip_range           | 0.1         |
|    entropy_loss         | -3.41       |
|    explained_variance   | 0.855       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.0349      |
|    n_updates            | 16          |
|    policy_gradient_loss | -0.00863    |
|    value_loss           | 0.134       |
-----------------------------------------
Early stopping at step 6 due to reaching max kl: 0.03
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 37.9        |
|    ep_rew_mean          | 112         |
| time/                   |             |
|    fps                  | 434         |
|    iterations           | 4           |
|    time_elapsed         | 452         |
|    total_timesteps      | 196608      |
| train/                  |             |
|    approx_kl            | 0.014318604 |
|    clip_fraction        | 0.491       |
|    clip_range           | 0.1         |
|    entropy_loss         | -3.39       |
|    explained_variance   | 0.852       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.0242      |
|    n_updates            | 23          |
|    policy_gradient_loss | -0.00659    |
|    value_loss           | 0.14        |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 38.1        |
|    ep_rew_mean          | 114         |
| time/                   |             |
|    fps                  | 403         |
|    iterations           | 5           |
|    time_elapsed         | 609         |
|    total_timesteps      | 245760      |
| train/                  |             |
|    approx_kl            | 0.015166431 |
|    clip_fraction        | 0.503       |
|    clip_range           | 0.1         |
|    entropy_loss         | -3.38       |
|    explained_variance   | 0.857       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.011       |
|    n_updates            | 31          |
|    policy_gradient_loss | -0.00928    |
|    value_loss           | 0.133       |
-----------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 37.9      |
|    ep_rew_mean          | 108       |
| time/                   |           |
|    fps                  | 387       |
|    iterations           | 6         |
|    time_elapsed         | 761       |
|    total_timesteps      | 294912    |
| train/                  |           |
|    approx_kl            | 0.0160965 |
|    clip_fraction        | 0.515     |
|    clip_range           | 0.1       |
|    entropy_loss         | -3.36     |
|    explained_variance   | 0.855     |
|    learning_rate        | 0.0003    |
|    loss                 | -0.000958 |
|    n_updates            | 39        |
|    policy_gradient_loss | -0.0102   |
|    value_loss           | 0.136     |
---------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 37.9        |
|    ep_rew_mean          | 108         |
| time/                   |             |
|    fps                  | 403         |
|    iterations           | 7           |
|    time_elapsed         | 851         |
|    total_timesteps      | 344064      |
| train/                  |             |
|    approx_kl            | 0.016743785 |
|    clip_fraction        | 0.52        |
|    clip_range           | 0.1         |
|    entropy_loss         | -3.35       |
|    explained_variance   | 0.856       |
|    learning_rate        | 0.0003      |
|    loss                 | -0.00209    |
|    n_updates            | 47          |
|    policy_gradient_loss | -0.01       |
|    value_loss           | 0.131       |
-----------------------------------------
INFO:train_ppo_vecnorm:Modelo guardado en best/ppo_ablation/ppo_conservative_clip_kl/seed_42/best/ppo_yahtzee_vecnorm_final y estadisticas de normalizacion en best/ppo_ablation/ppo_conservative_clip_kl/seed_42/best/ppo_vecnorm_stats.pkl
INFO:final_evaluate_rl:Autodeteccion: modelo=best/ppo_ablation/ppo_conservative_clip_kl/seed_42/best/ppo_yahtzee_vecnorm_final, stats=best/ppo_ablation/ppo_conservative_clip_kl/seed_42/best/ppo_vecnorm_stats.pkl, algo=ppo
INFO:final_evaluate_rl:Cargando modelo: best/ppo_ablation/ppo_conservative_clip_kl/seed_42/best/ppo_yahtzee_vecnorm_final
INFO:final_evaluate_rl:Algo detectado/forzado: ppo
INFO:final_evaluate_rl:Evaluando el modelo con recompensas SIN normalizar(evaluacion segura)...
INFO:final_evaluate_rl:Episode 1: Recompensa del episodio: 107.27049920585705, Puntuacion final: 109.0
INFO:final_evaluate_rl:Episode 2: Recompensa del episodio: 102.85100050759502, Puntuacion final: 106.0
INFO:final_evaluate_rl:Episode 3: Recompensa del episodio: 115.4260005960823, Puntuacion final: 117.0
INFO:final_evaluate_rl:Episode 4: Recompensa del episodio: 114.43400022853166, Puntuacion final: 116.0
INFO:final_evaluate_rl:Episode 5: Recompensa del episodio: 111.2305004389491, Puntuacion final: 113.0
INFO:final_evaluate_rl:Episode 6: Recompensa del episodio: 114.08049922651844, Puntuacion final: 116.0
INFO:final_evaluate_rl:Episode 7: Recompensa del episodio: 140.31499757035635, Puntuacion final: 142.0
INFO:final_evaluate_rl:Episode 8: Recompensa del episodio: 147.68000079202466, Puntuacion final: 150.0
INFO:final_evaluate_rl:Episode 9: Recompensa del episodio: 167.82449955644552, Puntuacion final: 171.0
INFO:final_evaluate_rl:Episode 10: Recompensa del episodio: 103.4390014198143, Puntuacion final: 106.0
INFO:final_evaluate_rl:Episode 11: Recompensa del episodio: 139.0479999188683, Puntuacion final: 141.0
INFO:final_evaluate_rl:Episode 12: Recompensa del episodio: 135.9069998121122, Puntuacion final: 138.0
INFO:final_evaluate_rl:Episode 13: Recompensa del episodio: 74.10199928260408, Puntuacion final: 76.0
INFO:final_evaluate_rl:Episode 14: Recompensa del episodio: 109.10500114038587, Puntuacion final: 111.0
INFO:final_evaluate_rl:Episode 15: Recompensa del episodio: 172.47200318193063, Puntuacion final: 175.0
INFO:final_evaluate_rl:Episode 16: Recompensa del episodio: 97.38700048392639, Puntuacion final: 99.0
INFO:final_evaluate_rl:Episode 17: Recompensa del episodio: 144.56549995485693, Puntuacion final: 147.0
INFO:final_evaluate_rl:Episode 18: Recompensa del episodio: 104.65250012197066, Puntuacion final: 107.0
INFO:final_evaluate_rl:Episode 19: Recompensa del episodio: 86.36299939849414, Puntuacion final: 88.0
INFO:final_evaluate_rl:Episode 20: Recompensa del episodio: 98.7274991334416, Puntuacion final: 100.0
INFO:final_evaluate_rl:Episode 21: Recompensa del episodio: 171.99199908255832, Puntuacion final: 174.0
INFO:final_evaluate_rl:Episode 22: Recompensa del episodio: 70.95199986291118, Puntuacion final: 73.0
INFO:final_evaluate_rl:Episode 23: Recompensa del episodio: 147.97700290149078, Puntuacion final: 150.0
INFO:final_evaluate_rl:Episode 24: Recompensa del episodio: 111.95100033096969, Puntuacion final: 114.0
INFO:final_evaluate_rl:Episode 25: Recompensa del episodio: 102.46650047088042, Puntuacion final: 104.0
INFO:final_evaluate_rl:Episode 26: Recompensa del episodio: 159.3130012769252, Puntuacion final: 161.0
INFO:final_evaluate_rl:Episode 27: Recompensa del episodio: 146.287500213366, Puntuacion final: 149.0
INFO:final_evaluate_rl:Episode 28: Recompensa del episodio: 125.37949932692572, Puntuacion final: 127.0
INFO:final_evaluate_rl:Episode 29: Recompensa del episodio: 130.43950005620718, Puntuacion final: 132.0
INFO:final_evaluate_rl:Episode 30: Recompensa del episodio: 137.36199993733317, Puntuacion final: 139.0
INFO:final_evaluate_rl:Episode 31: Recompensa del episodio: 122.32400346989743, Puntuacion final: 125.0
INFO:final_evaluate_rl:Episode 32: Recompensa del episodio: 103.46749975648709, Puntuacion final: 106.0
INFO:final_evaluate_rl:Episode 33: Recompensa del episodio: 108.94249980943277, Puntuacion final: 111.0
INFO:final_evaluate_rl:Episode 34: Recompensa del episodio: 198.84250136371702, Puntuacion final: 201.0
INFO:final_evaluate_rl:Episode 35: Recompensa del episodio: 174.815999454353, Puntuacion final: 177.0
INFO:final_evaluate_rl:Episode 36: Recompensa del episodio: 123.33599789452273, Puntuacion final: 126.0
INFO:final_evaluate_rl:Episode 37: Recompensa del episodio: 112.32799997390248, Puntuacion final: 114.0
INFO:final_evaluate_rl:Episode 38: Recompensa del episodio: 153.90850071900059, Puntuacion final: 156.0
INFO:final_evaluate_rl:Episode 39: Recompensa del episodio: 132.4514995375648, Puntuacion final: 134.0
INFO:final_evaluate_rl:Episode 40: Recompensa del episodio: 97.65849837177666, Puntuacion final: 100.0
INFO:final_evaluate_rl:Episode 41: Recompensa del episodio: 91.35200014710426, Puntuacion final: 93.0
INFO:final_evaluate_rl:Episode 42: Recompensa del episodio: 135.5124991470948, Puntuacion final: 137.0
INFO:final_evaluate_rl:Episode 43: Recompensa del episodio: 167.83249900350347, Puntuacion final: 169.0
INFO:final_evaluate_rl:Episode 44: Recompensa del episodio: 146.02150084683672, Puntuacion final: 148.0
INFO:final_evaluate_rl:Episode 45: Recompensa del episodio: 90.71899954066612, Puntuacion final: 93.0
INFO:final_evaluate_rl:Episode 46: Recompensa del episodio: 114.04899754514918, Puntuacion final: 116.0
INFO:final_evaluate_rl:Episode 47: Recompensa del episodio: 126.70999972691061, Puntuacion final: 129.0
INFO:final_evaluate_rl:Episode 48: Recompensa del episodio: 173.78249894967303, Puntuacion final: 177.0
INFO:final_evaluate_rl:Episode 49: Recompensa del episodio: 141.54849976452533, Puntuacion final: 143.0
INFO:final_evaluate_rl:Episode 50: Recompensa del episodio: 135.83449874829967, Puntuacion final: 139.0
INFO:final_evaluate_rl:Metricas guardadas en ppo_vecnorm_final_evaluation_metrics.txt
Early stopping at step 7 due to reaching max kl: 0.03
Grafica guardada en best/ppo_ablation/ppo_conservative_clip_kl/seed_42/best/ppo_vecnorm_reward_evolution.png

Resumen:
  Recompensa media (sin normalizar): 126.8487
  Puntuacion final promedio:        128.9000
