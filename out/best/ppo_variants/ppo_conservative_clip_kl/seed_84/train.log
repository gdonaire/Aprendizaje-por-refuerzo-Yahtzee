INFO:train_ppo_vecnorm:Creando 8 entornos paralelos con VecNormalize...
INFO:train_ppo_vecnorm:Activando wrapper de reparacion de acciones invalidas durante TRAINING...
INFO:train_ppo_vecnorm:Aplicando VecNormalize (obs y reward normalizados)...
INFO:train_ppo_vecnorm:Entrenando PPO Fase 1 por 400000 timesteps...
Argumentos de entrenamiento:
  timesteps: 400000
  timesteps2: 400000
  timesteps3: 300000
  n_envs: 8
  seed: 84
  lr: 0.0003
  n_steps: 2048
  batch_size: 64
  n_epochs: 8
  gamma: 0.99
  gae_lambda: 0.95
  ent_coef: 0.02
  clip_range: 0.1
  vf_coef: 0.5
  max_grad_norm: 0.5
  target_kl: 0.02
  use_sde: False
  sde_sample_freq: -1
  policy_arch: {"pi":[256, 256], "vf":[256, 256]}
  eval_episodes: 50
  best_dir: best/ppo_ablation/ppo_conservative_clip_kl/seed_84/best
  plot_ma_long: 200
  repair_actions_training: True
Using cpu device
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 33.3     |
|    ep_rew_mean     | 78.4     |
| time/              |          |
|    fps             | 1749     |
|    iterations      | 1        |
|    time_elapsed    | 9        |
|    total_timesteps | 16384    |
---------------------------------
Early stopping at step 5 due to reaching max kl: 0.04
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 33.4        |
|    ep_rew_mean          | 83.9        |
| time/                   |             |
|    fps                  | 1182        |
|    iterations           | 2           |
|    time_elapsed         | 27          |
|    total_timesteps      | 32768       |
| train/                  |             |
|    approx_kl            | 0.007035259 |
|    clip_fraction        | 0.259       |
|    clip_range           | 0.1         |
|    entropy_loss         | -3.78       |
|    explained_variance   | -0.411      |
|    learning_rate        | 0.0003      |
|    loss                 | 0.0696      |
|    n_updates            | 6           |
|    policy_gradient_loss | -0.00703    |
|    value_loss           | 0.229       |
-----------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 34.1         |
|    ep_rew_mean          | 80           |
| time/                   |              |
|    fps                  | 917          |
|    iterations           | 3            |
|    time_elapsed         | 53           |
|    total_timesteps      | 49152        |
| train/                  |              |
|    approx_kl            | 0.0054543503 |
|    clip_fraction        | 0.287        |
|    clip_range           | 0.1          |
|    entropy_loss         | -3.77        |
|    explained_variance   | 0.667        |
|    learning_rate        | 0.0003       |
|    loss                 | -0.0304      |
|    n_updates            | 14           |
|    policy_gradient_loss | -0.00827     |
|    value_loss           | 0.191        |
------------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 33.4         |
|    ep_rew_mean          | 84.2         |
| time/                   |              |
|    fps                  | 805          |
|    iterations           | 4            |
|    time_elapsed         | 81           |
|    total_timesteps      | 65536        |
| train/                  |              |
|    approx_kl            | 0.0050227926 |
|    clip_fraction        | 0.284        |
|    clip_range           | 0.1          |
|    entropy_loss         | -3.76        |
|    explained_variance   | 0.752        |
|    learning_rate        | 0.0003       |
|    loss                 | -0.02        |
|    n_updates            | 22           |
|    policy_gradient_loss | -0.00914     |
|    value_loss           | 0.191        |
------------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 34.2         |
|    ep_rew_mean          | 84.1         |
| time/                   |              |
|    fps                  | 778          |
|    iterations           | 5            |
|    time_elapsed         | 105          |
|    total_timesteps      | 81920        |
| train/                  |              |
|    approx_kl            | 0.0051879836 |
|    clip_fraction        | 0.295        |
|    clip_range           | 0.1          |
|    entropy_loss         | -3.76        |
|    explained_variance   | 0.792        |
|    learning_rate        | 0.0003       |
|    loss                 | 0.0166       |
|    n_updates            | 30           |
|    policy_gradient_loss | -0.00943     |
|    value_loss           | 0.161        |
------------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 34.4         |
|    ep_rew_mean          | 90.8         |
| time/                   |              |
|    fps                  | 753          |
|    iterations           | 6            |
|    time_elapsed         | 130          |
|    total_timesteps      | 98304        |
| train/                  |              |
|    approx_kl            | 0.0054365043 |
|    clip_fraction        | 0.302        |
|    clip_range           | 0.1          |
|    entropy_loss         | -3.75        |
|    explained_variance   | 0.803        |
|    learning_rate        | 0.0003       |
|    loss                 | -0.0161      |
|    n_updates            | 38           |
|    policy_gradient_loss | -0.00976     |
|    value_loss           | 0.167        |
------------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 34.4        |
|    ep_rew_mean          | 90.5        |
| time/                   |             |
|    fps                  | 764         |
|    iterations           | 7           |
|    time_elapsed         | 149         |
|    total_timesteps      | 114688      |
| train/                  |             |
|    approx_kl            | 0.005503827 |
|    clip_fraction        | 0.304       |
|    clip_range           | 0.1         |
|    entropy_loss         | -3.74       |
|    explained_variance   | 0.773       |
|    learning_rate        | 0.0003      |
|    loss                 | -0.00311    |
|    n_updates            | 46          |
|    policy_gradient_loss | -0.0106     |
|    value_loss           | 0.194       |
-----------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 35.3         |
|    ep_rew_mean          | 91.4         |
| time/                   |              |
|    fps                  | 772          |
|    iterations           | 8            |
|    time_elapsed         | 169          |
|    total_timesteps      | 131072       |
| train/                  |              |
|    approx_kl            | 0.0059239017 |
|    clip_fraction        | 0.317        |
|    clip_range           | 0.1          |
|    entropy_loss         | -3.73        |
|    explained_variance   | 0.802        |
|    learning_rate        | 0.0003       |
|    loss                 | 0.00911      |
|    n_updates            | 54           |
|    policy_gradient_loss | -0.0117      |
|    value_loss           | 0.16         |
------------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 35.1        |
|    ep_rew_mean          | 91          |
| time/                   |             |
|    fps                  | 778         |
|    iterations           | 9           |
|    time_elapsed         | 189         |
|    total_timesteps      | 147456      |
| train/                  |             |
|    approx_kl            | 0.005520658 |
|    clip_fraction        | 0.312       |
|    clip_range           | 0.1         |
|    entropy_loss         | -3.72       |
|    explained_variance   | 0.807       |
|    learning_rate        | 0.0003      |
|    loss                 | -0.0262     |
|    n_updates            | 62          |
|    policy_gradient_loss | -0.0111     |
|    value_loss           | 0.165       |
-----------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 35.5         |
|    ep_rew_mean          | 91.2         |
| time/                   |              |
|    fps                  | 784          |
|    iterations           | 10           |
|    time_elapsed         | 208          |
|    total_timesteps      | 163840       |
| train/                  |              |
|    approx_kl            | 0.0059478716 |
|    clip_fraction        | 0.321        |
|    clip_range           | 0.1          |
|    entropy_loss         | -3.72        |
|    explained_variance   | 0.809        |
|    learning_rate        | 0.0003       |
|    loss                 | -0.00126     |
|    n_updates            | 70           |
|    policy_gradient_loss | -0.012       |
|    value_loss           | 0.164        |
------------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 35.6         |
|    ep_rew_mean          | 98.7         |
| time/                   |              |
|    fps                  | 787          |
|    iterations           | 11           |
|    time_elapsed         | 228          |
|    total_timesteps      | 180224       |
| train/                  |              |
|    approx_kl            | 0.0060931197 |
|    clip_fraction        | 0.329        |
|    clip_range           | 0.1          |
|    entropy_loss         | -3.71        |
|    explained_variance   | 0.81         |
|    learning_rate        | 0.0003       |
|    loss                 | -0.00347     |
|    n_updates            | 78           |
|    policy_gradient_loss | -0.0123      |
|    value_loss           | 0.174        |
------------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 35.7        |
|    ep_rew_mean          | 94.4        |
| time/                   |             |
|    fps                  | 791         |
|    iterations           | 12          |
|    time_elapsed         | 248         |
|    total_timesteps      | 196608      |
| train/                  |             |
|    approx_kl            | 0.006596445 |
|    clip_fraction        | 0.342       |
|    clip_range           | 0.1         |
|    entropy_loss         | -3.7        |
|    explained_variance   | 0.808       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.00253     |
|    n_updates            | 86          |
|    policy_gradient_loss | -0.0135     |
|    value_loss           | 0.166       |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 35.8        |
|    ep_rew_mean          | 97          |
| time/                   |             |
|    fps                  | 794         |
|    iterations           | 13          |
|    time_elapsed         | 267         |
|    total_timesteps      | 212992      |
| train/                  |             |
|    approx_kl            | 0.006750842 |
|    clip_fraction        | 0.343       |
|    clip_range           | 0.1         |
|    entropy_loss         | -3.69       |
|    explained_variance   | 0.814       |
|    learning_rate        | 0.0003      |
|    loss                 | -0.0295     |
|    n_updates            | 94          |
|    policy_gradient_loss | -0.0141     |
|    value_loss           | 0.152       |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 35.9        |
|    ep_rew_mean          | 98.5        |
| time/                   |             |
|    fps                  | 797         |
|    iterations           | 14          |
|    time_elapsed         | 287         |
|    total_timesteps      | 229376      |
| train/                  |             |
|    approx_kl            | 0.006926669 |
|    clip_fraction        | 0.347       |
|    clip_range           | 0.1         |
|    entropy_loss         | -3.68       |
|    explained_variance   | 0.823       |
|    learning_rate        | 0.0003      |
|    loss                 | -0.0147     |
|    n_updates            | 102         |
|    policy_gradient_loss | -0.0142     |
|    value_loss           | 0.15        |
-----------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 36.3         |
|    ep_rew_mean          | 101          |
| time/                   |              |
|    fps                  | 799          |
|    iterations           | 15           |
|    time_elapsed         | 307          |
|    total_timesteps      | 245760       |
| train/                  |              |
|    approx_kl            | 0.0071221255 |
|    clip_fraction        | 0.355        |
|    clip_range           | 0.1          |
|    entropy_loss         | -3.66        |
|    explained_variance   | 0.816        |
|    learning_rate        | 0.0003       |
|    loss                 | -0.0333      |
|    n_updates            | 110          |
|    policy_gradient_loss | -0.015       |
|    value_loss           | 0.156        |
------------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 36.4       |
|    ep_rew_mean          | 98.1       |
| time/                   |            |
|    fps                  | 784        |
|    iterations           | 16         |
|    time_elapsed         | 334        |
|    total_timesteps      | 262144     |
| train/                  |            |
|    approx_kl            | 0.00783439 |
|    clip_fraction        | 0.37       |
|    clip_range           | 0.1        |
|    entropy_loss         | -3.65      |
|    explained_variance   | 0.826      |
|    learning_rate        | 0.0003     |
|    loss                 | -0.0256    |
|    n_updates            | 118        |
|    policy_gradient_loss | -0.016     |
|    value_loss           | 0.144      |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 36.4        |
|    ep_rew_mean          | 101         |
| time/                   |             |
|    fps                  | 770         |
|    iterations           | 17          |
|    time_elapsed         | 361         |
|    total_timesteps      | 278528      |
| train/                  |             |
|    approx_kl            | 0.007815283 |
|    clip_fraction        | 0.368       |
|    clip_range           | 0.1         |
|    entropy_loss         | -3.64       |
|    explained_variance   | 0.822       |
|    learning_rate        | 0.0003      |
|    loss                 | -0.0336     |
|    n_updates            | 126         |
|    policy_gradient_loss | -0.0152     |
|    value_loss           | 0.16        |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 36.4       |
|    ep_rew_mean          | 98.8       |
| time/                   |            |
|    fps                  | 759        |
|    iterations           | 18         |
|    time_elapsed         | 388        |
|    total_timesteps      | 294912     |
| train/                  |            |
|    approx_kl            | 0.00821918 |
|    clip_fraction        | 0.382      |
|    clip_range           | 0.1        |
|    entropy_loss         | -3.63      |
|    explained_variance   | 0.83       |
|    learning_rate        | 0.0003     |
|    loss                 | -0.0555    |
|    n_updates            | 134        |
|    policy_gradient_loss | -0.0159    |
|    value_loss           | 0.152      |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 36.6        |
|    ep_rew_mean          | 102         |
| time/                   |             |
|    fps                  | 742         |
|    iterations           | 19          |
|    time_elapsed         | 419         |
|    total_timesteps      | 311296      |
| train/                  |             |
|    approx_kl            | 0.008479492 |
|    clip_fraction        | 0.385       |
|    clip_range           | 0.1         |
|    entropy_loss         | -3.62       |
|    explained_variance   | 0.83        |
|    learning_rate        | 0.0003      |
|    loss                 | -0.0236     |
|    n_updates            | 142         |
|    policy_gradient_loss | -0.0161     |
|    value_loss           | 0.145       |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 36.5        |
|    ep_rew_mean          | 108         |
| time/                   |             |
|    fps                  | 741         |
|    iterations           | 20          |
|    time_elapsed         | 442         |
|    total_timesteps      | 327680      |
| train/                  |             |
|    approx_kl            | 0.008705435 |
|    clip_fraction        | 0.398       |
|    clip_range           | 0.1         |
|    entropy_loss         | -3.61       |
|    explained_variance   | 0.834       |
|    learning_rate        | 0.0003      |
|    loss                 | -0.0353     |
|    n_updates            | 150         |
|    policy_gradient_loss | -0.0168     |
|    value_loss           | 0.139       |
-----------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 36.5         |
|    ep_rew_mean          | 97.1         |
| time/                   |              |
|    fps                  | 739          |
|    iterations           | 21           |
|    time_elapsed         | 465          |
|    total_timesteps      | 344064       |
| train/                  |              |
|    approx_kl            | 0.0093248645 |
|    clip_fraction        | 0.402        |
|    clip_range           | 0.1          |
|    entropy_loss         | -3.6         |
|    explained_variance   | 0.838        |
|    learning_rate        | 0.0003       |
|    loss                 | -0.047       |
|    n_updates            | 158          |
|    policy_gradient_loss | -0.0173      |
|    value_loss           | 0.135        |
------------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 36.5        |
|    ep_rew_mean          | 107         |
| time/                   |             |
|    fps                  | 735         |
|    iterations           | 22          |
|    time_elapsed         | 490         |
|    total_timesteps      | 360448      |
| train/                  |             |
|    approx_kl            | 0.009716436 |
|    clip_fraction        | 0.408       |
|    clip_range           | 0.1         |
|    entropy_loss         | -3.59       |
|    explained_variance   | 0.841       |
|    learning_rate        | 0.0003      |
|    loss                 | -0.0546     |
|    n_updates            | 166         |
|    policy_gradient_loss | -0.0178     |
|    value_loss           | 0.131       |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 37          |
|    ep_rew_mean          | 100         |
| time/                   |             |
|    fps                  | 732         |
|    iterations           | 23          |
|    time_elapsed         | 514         |
|    total_timesteps      | 376832      |
| train/                  |             |
|    approx_kl            | 0.009991229 |
|    clip_fraction        | 0.414       |
|    clip_range           | 0.1         |
|    entropy_loss         | -3.58       |
|    explained_variance   | 0.829       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.0012      |
|    n_updates            | 174         |
|    policy_gradient_loss | -0.0176     |
|    value_loss           | 0.147       |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 37.2       |
|    ep_rew_mean          | 99.8       |
| time/                   |            |
|    fps                  | 727        |
|    iterations           | 24         |
|    time_elapsed         | 540        |
|    total_timesteps      | 393216     |
| train/                  |            |
|    approx_kl            | 0.00995231 |
|    clip_fraction        | 0.416      |
|    clip_range           | 0.1        |
|    entropy_loss         | -3.58      |
|    explained_variance   | 0.824      |
|    learning_rate        | 0.0003     |
|    loss                 | -0.0584    |
|    n_updates            | 182        |
|    policy_gradient_loss | -0.0176    |
|    value_loss           | 0.143      |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 36.8       |
|    ep_rew_mean          | 106        |
| time/                   |            |
|    fps                  | 723        |
|    iterations           | 25         |
|    time_elapsed         | 565        |
|    total_timesteps      | 409600     |
| train/                  |            |
|    approx_kl            | 0.01035705 |
|    clip_fraction        | 0.422      |
|    clip_range           | 0.1        |
|    entropy_loss         | -3.57      |
|    explained_variance   | 0.818      |
|    learning_rate        | 0.0003     |
|    loss                 | -0.0318    |
|    n_updates            | 190        |
|    policy_gradient_loss | -0.0184    |
|    value_loss           | 0.149      |
----------------------------------------
INFO:train_ppo_vecnorm:Entrenando PPO Fase 2 por 400000 timesteps...
Using cpu device
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 36.8     |
|    ep_rew_mean     | 109      |
| time/              |          |
|    fps             | 1577     |
|    iterations      | 1        |
|    time_elapsed    | 20       |
|    total_timesteps | 32768    |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 37          |
|    ep_rew_mean          | 106         |
| time/                   |             |
|    fps                  | 940         |
|    iterations           | 2           |
|    time_elapsed         | 69          |
|    total_timesteps      | 65536       |
| train/                  |             |
|    approx_kl            | 0.010438302 |
|    clip_fraction        | 0.428       |
|    clip_range           | 0.1         |
|    entropy_loss         | -3.55       |
|    explained_variance   | 0.822       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.0135      |
|    n_updates            | 8           |
|    policy_gradient_loss | -0.0105     |
|    value_loss           | 0.153       |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 37.4        |
|    ep_rew_mean          | 102         |
| time/                   |             |
|    fps                  | 809         |
|    iterations           | 3           |
|    time_elapsed         | 121         |
|    total_timesteps      | 98304       |
| train/                  |             |
|    approx_kl            | 0.010605197 |
|    clip_fraction        | 0.431       |
|    clip_range           | 0.1         |
|    entropy_loss         | -3.53       |
|    explained_variance   | 0.839       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.0171      |
|    n_updates            | 16          |
|    policy_gradient_loss | -0.0104     |
|    value_loss           | 0.142       |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 37.1        |
|    ep_rew_mean          | 107         |
| time/                   |             |
|    fps                  | 788         |
|    iterations           | 4           |
|    time_elapsed         | 166         |
|    total_timesteps      | 131072      |
| train/                  |             |
|    approx_kl            | 0.011016641 |
|    clip_fraction        | 0.432       |
|    clip_range           | 0.1         |
|    entropy_loss         | -3.53       |
|    explained_variance   | 0.849       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.0367      |
|    n_updates            | 24          |
|    policy_gradient_loss | -0.011      |
|    value_loss           | 0.136       |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 37.3        |
|    ep_rew_mean          | 113         |
| time/                   |             |
|    fps                  | 712         |
|    iterations           | 5           |
|    time_elapsed         | 230         |
|    total_timesteps      | 163840      |
| train/                  |             |
|    approx_kl            | 0.011299448 |
|    clip_fraction        | 0.44        |
|    clip_range           | 0.1         |
|    entropy_loss         | -3.52       |
|    explained_variance   | 0.848       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.00659     |
|    n_updates            | 32          |
|    policy_gradient_loss | -0.0114     |
|    value_loss           | 0.139       |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 37.4        |
|    ep_rew_mean          | 105         |
| time/                   |             |
|    fps                  | 688         |
|    iterations           | 6           |
|    time_elapsed         | 285         |
|    total_timesteps      | 196608      |
| train/                  |             |
|    approx_kl            | 0.011898283 |
|    clip_fraction        | 0.446       |
|    clip_range           | 0.1         |
|    entropy_loss         | -3.51       |
|    explained_variance   | 0.837       |
|    learning_rate        | 0.0003      |
|    loss                 | -0.00199    |
|    n_updates            | 40          |
|    policy_gradient_loss | -0.0124     |
|    value_loss           | 0.146       |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 37.4       |
|    ep_rew_mean          | 107        |
| time/                   |            |
|    fps                  | 685        |
|    iterations           | 7          |
|    time_elapsed         | 334        |
|    total_timesteps      | 229376     |
| train/                  |            |
|    approx_kl            | 0.01182225 |
|    clip_fraction        | 0.451      |
|    clip_range           | 0.1        |
|    entropy_loss         | -3.5       |
|    explained_variance   | 0.845      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.0229     |
|    n_updates            | 48         |
|    policy_gradient_loss | -0.0122    |
|    value_loss           | 0.14       |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 37.3        |
|    ep_rew_mean          | 115         |
| time/                   |             |
|    fps                  | 679         |
|    iterations           | 8           |
|    time_elapsed         | 385         |
|    total_timesteps      | 262144      |
| train/                  |             |
|    approx_kl            | 0.012419451 |
|    clip_fraction        | 0.457       |
|    clip_range           | 0.1         |
|    entropy_loss         | -3.49       |
|    explained_variance   | 0.84        |
|    learning_rate        | 0.0003      |
|    loss                 | -0.00369    |
|    n_updates            | 56          |
|    policy_gradient_loss | -0.0128     |
|    value_loss           | 0.138       |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 37.4        |
|    ep_rew_mean          | 112         |
| time/                   |             |
|    fps                  | 670         |
|    iterations           | 9           |
|    time_elapsed         | 439         |
|    total_timesteps      | 294912      |
| train/                  |             |
|    approx_kl            | 0.012960613 |
|    clip_fraction        | 0.466       |
|    clip_range           | 0.1         |
|    entropy_loss         | -3.48       |
|    explained_variance   | 0.841       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.00432     |
|    n_updates            | 64          |
|    policy_gradient_loss | -0.0126     |
|    value_loss           | 0.139       |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 37.3        |
|    ep_rew_mean          | 109         |
| time/                   |             |
|    fps                  | 671         |
|    iterations           | 10          |
|    time_elapsed         | 487         |
|    total_timesteps      | 327680      |
| train/                  |             |
|    approx_kl            | 0.013132619 |
|    clip_fraction        | 0.469       |
|    clip_range           | 0.1         |
|    entropy_loss         | -3.46       |
|    explained_variance   | 0.855       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.0198      |
|    n_updates            | 72          |
|    policy_gradient_loss | -0.013      |
|    value_loss           | 0.131       |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 37.6        |
|    ep_rew_mean          | 104         |
| time/                   |             |
|    fps                  | 674         |
|    iterations           | 11          |
|    time_elapsed         | 534         |
|    total_timesteps      | 360448      |
| train/                  |             |
|    approx_kl            | 0.013825385 |
|    clip_fraction        | 0.473       |
|    clip_range           | 0.1         |
|    entropy_loss         | -3.45       |
|    explained_variance   | 0.849       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.0124      |
|    n_updates            | 80          |
|    policy_gradient_loss | -0.0127     |
|    value_loss           | 0.138       |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 37.5        |
|    ep_rew_mean          | 110         |
| time/                   |             |
|    fps                  | 671         |
|    iterations           | 12          |
|    time_elapsed         | 585         |
|    total_timesteps      | 393216      |
| train/                  |             |
|    approx_kl            | 0.014030622 |
|    clip_fraction        | 0.479       |
|    clip_range           | 0.1         |
|    entropy_loss         | -3.44       |
|    explained_variance   | 0.846       |
|    learning_rate        | 0.0003      |
|    loss                 | -0.0239     |
|    n_updates            | 88          |
|    policy_gradient_loss | -0.0138     |
|    value_loss           | 0.138       |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 37.7        |
|    ep_rew_mean          | 112         |
| time/                   |             |
|    fps                  | 670         |
|    iterations           | 13          |
|    time_elapsed         | 635         |
|    total_timesteps      | 425984      |
| train/                  |             |
|    approx_kl            | 0.013785272 |
|    clip_fraction        | 0.485       |
|    clip_range           | 0.1         |
|    entropy_loss         | -3.43       |
|    explained_variance   | 0.858       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.00868     |
|    n_updates            | 96          |
|    policy_gradient_loss | -0.0135     |
|    value_loss           | 0.127       |
-----------------------------------------
INFO:train_ppo_vecnorm:Entrenando PPO Fase 3 por 300000 timesteps...
Using cpu device
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 37.8     |
|    ep_rew_mean     | 106      |
| time/              |          |
|    fps             | 1689     |
|    iterations      | 1        |
|    time_elapsed    | 29       |
|    total_timesteps | 49152    |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 37.6        |
|    ep_rew_mean          | 111         |
| time/                   |             |
|    fps                  | 964         |
|    iterations           | 2           |
|    time_elapsed         | 101         |
|    total_timesteps      | 98304       |
| train/                  |             |
|    approx_kl            | 0.015033375 |
|    clip_fraction        | 0.501       |
|    clip_range           | 0.1         |
|    entropy_loss         | -3.41       |
|    explained_variance   | 0.847       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.0235      |
|    n_updates            | 8           |
|    policy_gradient_loss | -0.00895    |
|    value_loss           | 0.139       |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 37.7       |
|    ep_rew_mean          | 114        |
| time/                   |            |
|    fps                  | 798        |
|    iterations           | 3          |
|    time_elapsed         | 184        |
|    total_timesteps      | 147456     |
| train/                  |            |
|    approx_kl            | 0.01495044 |
|    clip_fraction        | 0.499      |
|    clip_range           | 0.1        |
|    entropy_loss         | -3.39      |
|    explained_variance   | 0.85       |
|    learning_rate        | 0.0003     |
|    loss                 | 0.0257     |
|    n_updates            | 16         |
|    policy_gradient_loss | -0.00927   |
|    value_loss           | 0.133      |
----------------------------------------
Early stopping at step 7 due to reaching max kl: 0.03
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 37.8        |
|    ep_rew_mean          | 115         |
| time/                   |             |
|    fps                  | 765         |
|    iterations           | 4           |
|    time_elapsed         | 256         |
|    total_timesteps      | 196608      |
| train/                  |             |
|    approx_kl            | 0.015002477 |
|    clip_fraction        | 0.496       |
|    clip_range           | 0.1         |
|    entropy_loss         | -3.38       |
|    explained_variance   | 0.86        |
|    learning_rate        | 0.0003      |
|    loss                 | 0.00651     |
|    n_updates            | 24          |
|    policy_gradient_loss | -0.00785    |
|    value_loss           | 0.135       |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 37.7        |
|    ep_rew_mean          | 110         |
| time/                   |             |
|    fps                  | 732         |
|    iterations           | 5           |
|    time_elapsed         | 335         |
|    total_timesteps      | 245760      |
| train/                  |             |
|    approx_kl            | 0.015969584 |
|    clip_fraction        | 0.512       |
|    clip_range           | 0.1         |
|    entropy_loss         | -3.37       |
|    explained_variance   | 0.861       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.0221      |
|    n_updates            | 32          |
|    policy_gradient_loss | -0.00972    |
|    value_loss           | 0.132       |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 37.9        |
|    ep_rew_mean          | 109         |
| time/                   |             |
|    fps                  | 717         |
|    iterations           | 6           |
|    time_elapsed         | 410         |
|    total_timesteps      | 294912      |
| train/                  |             |
|    approx_kl            | 0.015799388 |
|    clip_fraction        | 0.511       |
|    clip_range           | 0.1         |
|    entropy_loss         | -3.36       |
|    explained_variance   | 0.853       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.00511     |
|    n_updates            | 40          |
|    policy_gradient_loss | -0.00986    |
|    value_loss           | 0.135       |
-----------------------------------------
Early stopping at step 6 due to reaching max kl: 0.03
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 37.7        |
|    ep_rew_mean          | 116         |
| time/                   |             |
|    fps                  | 714         |
|    iterations           | 7           |
|    time_elapsed         | 481         |
|    total_timesteps      | 344064      |
| train/                  |             |
|    approx_kl            | 0.015782489 |
|    clip_fraction        | 0.505       |
|    clip_range           | 0.1         |
|    entropy_loss         | -3.34       |
|    explained_variance   | 0.861       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.0197      |
|    n_updates            | 47          |
|    policy_gradient_loss | -0.00689    |
|    value_loss           | 0.134       |
-----------------------------------------
INFO:train_ppo_vecnorm:Modelo guardado en best/ppo_ablation/ppo_conservative_clip_kl/seed_84/best/ppo_yahtzee_vecnorm_final y estadisticas de normalizacion en best/ppo_ablation/ppo_conservative_clip_kl/seed_84/best/ppo_vecnorm_stats.pkl
INFO:final_evaluate_rl:Autodeteccion: modelo=best/ppo_ablation/ppo_conservative_clip_kl/seed_84/best/ppo_yahtzee_vecnorm_final, stats=best/ppo_ablation/ppo_conservative_clip_kl/seed_84/best/ppo_vecnorm_stats.pkl, algo=ppo
INFO:final_evaluate_rl:Cargando modelo: best/ppo_ablation/ppo_conservative_clip_kl/seed_84/best/ppo_yahtzee_vecnorm_final
INFO:final_evaluate_rl:Algo detectado/forzado: ppo
INFO:final_evaluate_rl:Evaluando el modelo con recompensas SIN normalizar(evaluacion segura)...
INFO:final_evaluate_rl:Episode 1: Recompensa del episodio: 86.7185005529318, Puntuacion final: 89.0
INFO:final_evaluate_rl:Episode 2: Recompensa del episodio: 121.40999924310017, Puntuacion final: 123.0
INFO:final_evaluate_rl:Episode 3: Recompensa del episodio: 99.2504990703892, Puntuacion final: 101.0
INFO:final_evaluate_rl:Episode 4: Recompensa del episodio: 139.10899778595194, Puntuacion final: 141.0
INFO:final_evaluate_rl:Episode 5: Recompensa del episodio: 149.79699925438035, Puntuacion final: 153.0
INFO:final_evaluate_rl:Episode 6: Recompensa del episodio: 127.53449959831778, Puntuacion final: 129.0
INFO:final_evaluate_rl:Episode 7: Recompensa del episodio: 96.72750010609161, Puntuacion final: 99.0
INFO:final_evaluate_rl:Episode 8: Recompensa del episodio: 115.80649907933548, Puntuacion final: 120.0
INFO:final_evaluate_rl:Episode 9: Recompensa del episodio: 163.59150029951707, Puntuacion final: 166.0
INFO:final_evaluate_rl:Episode 10: Recompensa del episodio: 131.61349915887695, Puntuacion final: 134.0
INFO:final_evaluate_rl:Episode 11: Recompensa del episodio: 146.81399935856462, Puntuacion final: 150.0
INFO:final_evaluate_rl:Episode 12: Recompensa del episodio: 117.82749969448196, Puntuacion final: 121.0
INFO:final_evaluate_rl:Episode 13: Recompensa del episodio: 140.24350266554393, Puntuacion final: 142.0
INFO:final_evaluate_rl:Episode 14: Recompensa del episodio: 75.88700005458668, Puntuacion final: 80.0
INFO:final_evaluate_rl:Episode 15: Recompensa del episodio: 140.81899894482922, Puntuacion final: 145.0
INFO:final_evaluate_rl:Episode 16: Recompensa del episodio: 131.84650054154918, Puntuacion final: 135.0
INFO:final_evaluate_rl:Episode 17: Recompensa del episodio: 109.34500133607071, Puntuacion final: 111.0
INFO:final_evaluate_rl:Episode 18: Recompensa del episodio: 137.91049751697574, Puntuacion final: 140.0
INFO:final_evaluate_rl:Episode 19: Recompensa del episodio: 144.10099989920855, Puntuacion final: 146.0
INFO:final_evaluate_rl:Episode 20: Recompensa del episodio: 119.73299977183342, Puntuacion final: 121.0
INFO:final_evaluate_rl:Episode 21: Recompensa del episodio: 106.57400136592332, Puntuacion final: 109.0
INFO:final_evaluate_rl:Episode 22: Recompensa del episodio: 184.97850413573906, Puntuacion final: 187.0
INFO:final_evaluate_rl:Episode 23: Recompensa del episodio: 132.14849877671804, Puntuacion final: 134.0
INFO:final_evaluate_rl:Episode 24: Recompensa del episodio: 93.95850058604265, Puntuacion final: 96.0
INFO:final_evaluate_rl:Episode 25: Recompensa del episodio: 168.26250274432823, Puntuacion final: 171.0
INFO:final_evaluate_rl:Episode 26: Recompensa del episodio: 137.3045026450418, Puntuacion final: 139.0
INFO:final_evaluate_rl:Episode 27: Recompensa del episodio: 129.25349994772114, Puntuacion final: 131.0
INFO:final_evaluate_rl:Episode 28: Recompensa del episodio: 92.87749937735498, Puntuacion final: 96.0
INFO:final_evaluate_rl:Episode 29: Recompensa del episodio: 158.09349887497956, Puntuacion final: 160.0
INFO:final_evaluate_rl:Episode 30: Recompensa del episodio: 130.62200059194583, Puntuacion final: 133.0
INFO:final_evaluate_rl:Episode 31: Recompensa del episodio: 124.91399918112438, Puntuacion final: 127.0
INFO:final_evaluate_rl:Episode 32: Recompensa del episodio: 60.83149991813116, Puntuacion final: 64.0
INFO:final_evaluate_rl:Episode 33: Recompensa del episodio: 57.85600015439559, Puntuacion final: 61.0
INFO:final_evaluate_rl:Episode 34: Recompensa del episodio: 93.92849956266582, Puntuacion final: 96.0
INFO:final_evaluate_rl:Episode 35: Recompensa del episodio: 114.91649903077632, Puntuacion final: 117.0
INFO:final_evaluate_rl:Episode 36: Recompensa del episodio: 72.83899955335073, Puntuacion final: 76.0
INFO:final_evaluate_rl:Episode 37: Recompensa del episodio: 82.60999906179495, Puntuacion final: 84.0
INFO:final_evaluate_rl:Episode 38: Recompensa del episodio: 63.68249987158924, Puntuacion final: 65.0
INFO:final_evaluate_rl:Episode 39: Recompensa del episodio: 127.6540009030141, Puntuacion final: 130.0
INFO:final_evaluate_rl:Episode 40: Recompensa del episodio: 119.6134987201076, Puntuacion final: 121.0
INFO:final_evaluate_rl:Episode 41: Recompensa del episodio: 94.15800110029522, Puntuacion final: 96.0
INFO:final_evaluate_rl:Episode 42: Recompensa del episodio: 76.83799934160197, Puntuacion final: 80.0
INFO:final_evaluate_rl:Episode 43: Recompensa del episodio: 110.86249999632128, Puntuacion final: 113.0
INFO:final_evaluate_rl:Episode 44: Recompensa del episodio: 128.97949920827523, Puntuacion final: 131.0
INFO:final_evaluate_rl:Episode 45: Recompensa del episodio: 135.8205003736657, Puntuacion final: 139.0
INFO:final_evaluate_rl:Episode 46: Recompensa del episodio: 166.49399780319072, Puntuacion final: 168.0
INFO:final_evaluate_rl:Episode 47: Recompensa del episodio: 171.50699909578543, Puntuacion final: 174.0
INFO:final_evaluate_rl:Episode 48: Recompensa del episodio: 135.9914994876599, Puntuacion final: 138.0
INFO:final_evaluate_rl:Episode 49: Recompensa del episodio: 179.27300157840364, Puntuacion final: 181.0
INFO:final_evaluate_rl:Episode 50: Recompensa del episodio: 113.67150092340307, Puntuacion final: 115.0
INFO:final_evaluate_rl:Metricas guardadas en ppo_vecnorm_final_evaluation_metrics.txt
Early stopping at step 6 due to reaching max kl: 0.03
Grafica guardada en best/ppo_ablation/ppo_conservative_clip_kl/seed_84/best/ppo_vecnorm_reward_evolution.png

Resumen:
  Recompensa media (sin normalizar): 121.2520
  Puntuacion final promedio:        123.5600
