INFO:train_ppo_vecnorm:Creando 8 entornos paralelos con VecNormalize...
INFO:train_ppo_vecnorm:Activando wrapper de reparacion de acciones invalidas durante TRAINING...
INFO:train_ppo_vecnorm:Aplicando VecNormalize (obs y reward normalizados)...
INFO:train_ppo_vecnorm:Entrenando PPO Fase 1 por 400000 timesteps...
Argumentos de entrenamiento:
  timesteps: 400000
  timesteps2: 400000
  timesteps3: 300000
  n_envs: 8
  seed: 126
  lr: 0.0003
  n_steps: 2048
  batch_size: 64
  n_epochs: 8
  gamma: 0.99
  gae_lambda: 0.95
  ent_coef: 0.02
  clip_range: 0.1
  vf_coef: 0.5
  max_grad_norm: 0.5
  target_kl: 0.02
  use_sde: False
  sde_sample_freq: -1
  policy_arch: {"pi":[256, 256], "vf":[256, 256]}
  eval_episodes: 50
  best_dir: best/ppo_ablation/ppo_conservative_clip_kl/seed_126/best
  plot_ma_long: 200
  repair_actions_training: True
Using cpu device
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 32.8     |
|    ep_rew_mean     | 76.1     |
| time/              |          |
|    fps             | 1617     |
|    iterations      | 1        |
|    time_elapsed    | 10       |
|    total_timesteps | 16384    |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 33.6        |
|    ep_rew_mean          | 78.3        |
| time/                   |             |
|    fps                  | 936         |
|    iterations           | 2           |
|    time_elapsed         | 34          |
|    total_timesteps      | 32768       |
| train/                  |             |
|    approx_kl            | 0.005193753 |
|    clip_fraction        | 0.272       |
|    clip_range           | 0.1         |
|    entropy_loss         | -3.78       |
|    explained_variance   | 0.15        |
|    learning_rate        | 0.0003      |
|    loss                 | -0.0056     |
|    n_updates            | 8           |
|    policy_gradient_loss | -0.00787    |
|    value_loss           | 0.24        |
-----------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 33.6         |
|    ep_rew_mean          | 85           |
| time/                   |              |
|    fps                  | 844          |
|    iterations           | 3            |
|    time_elapsed         | 58           |
|    total_timesteps      | 49152        |
| train/                  |              |
|    approx_kl            | 0.0049836393 |
|    clip_fraction        | 0.283        |
|    clip_range           | 0.1          |
|    entropy_loss         | -3.77        |
|    explained_variance   | 0.679        |
|    learning_rate        | 0.0003       |
|    loss                 | -0.0267      |
|    n_updates            | 16           |
|    policy_gradient_loss | -0.00924     |
|    value_loss           | 0.184        |
------------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 34           |
|    ep_rew_mean          | 82.7         |
| time/                   |              |
|    fps                  | 763          |
|    iterations           | 4            |
|    time_elapsed         | 85           |
|    total_timesteps      | 65536        |
| train/                  |              |
|    approx_kl            | 0.0052100956 |
|    clip_fraction        | 0.285        |
|    clip_range           | 0.1          |
|    entropy_loss         | -3.77        |
|    explained_variance   | 0.748        |
|    learning_rate        | 0.0003       |
|    loss                 | -0.00621     |
|    n_updates            | 24           |
|    policy_gradient_loss | -0.00993     |
|    value_loss           | 0.189        |
------------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 34.3        |
|    ep_rew_mean          | 89.3        |
| time/                   |             |
|    fps                  | 743         |
|    iterations           | 5           |
|    time_elapsed         | 110         |
|    total_timesteps      | 81920       |
| train/                  |             |
|    approx_kl            | 0.005126615 |
|    clip_fraction        | 0.289       |
|    clip_range           | 0.1         |
|    entropy_loss         | -3.76       |
|    explained_variance   | 0.781       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.00373     |
|    n_updates            | 32          |
|    policy_gradient_loss | -0.0102     |
|    value_loss           | 0.179       |
-----------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 34.7         |
|    ep_rew_mean          | 89.6         |
| time/                   |              |
|    fps                  | 733          |
|    iterations           | 6            |
|    time_elapsed         | 134          |
|    total_timesteps      | 98304        |
| train/                  |              |
|    approx_kl            | 0.0053116214 |
|    clip_fraction        | 0.308        |
|    clip_range           | 0.1          |
|    entropy_loss         | -3.75        |
|    explained_variance   | 0.801        |
|    learning_rate        | 0.0003       |
|    loss                 | 0.0178       |
|    n_updates            | 40           |
|    policy_gradient_loss | -0.0109      |
|    value_loss           | 0.17         |
------------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 34.9         |
|    ep_rew_mean          | 94.8         |
| time/                   |              |
|    fps                  | 728          |
|    iterations           | 7            |
|    time_elapsed         | 157          |
|    total_timesteps      | 114688       |
| train/                  |              |
|    approx_kl            | 0.0056621674 |
|    clip_fraction        | 0.317        |
|    clip_range           | 0.1          |
|    entropy_loss         | -3.74        |
|    explained_variance   | 0.793        |
|    learning_rate        | 0.0003       |
|    loss                 | -0.00565     |
|    n_updates            | 48           |
|    policy_gradient_loss | -0.0117      |
|    value_loss           | 0.171        |
------------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 35           |
|    ep_rew_mean          | 91           |
| time/                   |              |
|    fps                  | 721          |
|    iterations           | 8            |
|    time_elapsed         | 181          |
|    total_timesteps      | 131072       |
| train/                  |              |
|    approx_kl            | 0.0059012636 |
|    clip_fraction        | 0.315        |
|    clip_range           | 0.1          |
|    entropy_loss         | -3.74        |
|    explained_variance   | 0.81         |
|    learning_rate        | 0.0003       |
|    loss                 | -0.0492      |
|    n_updates            | 56           |
|    policy_gradient_loss | -0.0115      |
|    value_loss           | 0.155        |
------------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 35           |
|    ep_rew_mean          | 95.4         |
| time/                   |              |
|    fps                  | 716          |
|    iterations           | 9            |
|    time_elapsed         | 205          |
|    total_timesteps      | 147456       |
| train/                  |              |
|    approx_kl            | 0.0060787946 |
|    clip_fraction        | 0.314        |
|    clip_range           | 0.1          |
|    entropy_loss         | -3.73        |
|    explained_variance   | 0.801        |
|    learning_rate        | 0.0003       |
|    loss                 | -0.0075      |
|    n_updates            | 64           |
|    policy_gradient_loss | -0.0115      |
|    value_loss           | 0.175        |
------------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 35.4        |
|    ep_rew_mean          | 94.9        |
| time/                   |             |
|    fps                  | 716         |
|    iterations           | 10          |
|    time_elapsed         | 228         |
|    total_timesteps      | 163840      |
| train/                  |             |
|    approx_kl            | 0.006272205 |
|    clip_fraction        | 0.335       |
|    clip_range           | 0.1         |
|    entropy_loss         | -3.72       |
|    explained_variance   | 0.809       |
|    learning_rate        | 0.0003      |
|    loss                 | -0.0214     |
|    n_updates            | 72          |
|    policy_gradient_loss | -0.0119     |
|    value_loss           | 0.168       |
-----------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 35.3         |
|    ep_rew_mean          | 90.5         |
| time/                   |              |
|    fps                  | 712          |
|    iterations           | 11           |
|    time_elapsed         | 252          |
|    total_timesteps      | 180224       |
| train/                  |              |
|    approx_kl            | 0.0061087096 |
|    clip_fraction        | 0.331        |
|    clip_range           | 0.1          |
|    entropy_loss         | -3.7         |
|    explained_variance   | 0.817        |
|    learning_rate        | 0.0003       |
|    loss                 | -0.0233      |
|    n_updates            | 80           |
|    policy_gradient_loss | -0.012       |
|    value_loss           | 0.152        |
------------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 35.6         |
|    ep_rew_mean          | 91.5         |
| time/                   |              |
|    fps                  | 711          |
|    iterations           | 12           |
|    time_elapsed         | 276          |
|    total_timesteps      | 196608       |
| train/                  |              |
|    approx_kl            | 0.0065410174 |
|    clip_fraction        | 0.334        |
|    clip_range           | 0.1          |
|    entropy_loss         | -3.69        |
|    explained_variance   | 0.826        |
|    learning_rate        | 0.0003       |
|    loss                 | 0.00116      |
|    n_updates            | 88           |
|    policy_gradient_loss | -0.0124      |
|    value_loss           | 0.149        |
------------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 35.9         |
|    ep_rew_mean          | 97.7         |
| time/                   |              |
|    fps                  | 707          |
|    iterations           | 13           |
|    time_elapsed         | 301          |
|    total_timesteps      | 212992       |
| train/                  |              |
|    approx_kl            | 0.0069468385 |
|    clip_fraction        | 0.35         |
|    clip_range           | 0.1          |
|    entropy_loss         | -3.68        |
|    explained_variance   | 0.824        |
|    learning_rate        | 0.0003       |
|    loss                 | -0.0321      |
|    n_updates            | 96           |
|    policy_gradient_loss | -0.0135      |
|    value_loss           | 0.148        |
------------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 36.7         |
|    ep_rew_mean          | 101          |
| time/                   |              |
|    fps                  | 697          |
|    iterations           | 14           |
|    time_elapsed         | 328          |
|    total_timesteps      | 229376       |
| train/                  |              |
|    approx_kl            | 0.0069888607 |
|    clip_fraction        | 0.354        |
|    clip_range           | 0.1          |
|    entropy_loss         | -3.68        |
|    explained_variance   | 0.818        |
|    learning_rate        | 0.0003       |
|    loss                 | -0.0116      |
|    n_updates            | 104          |
|    policy_gradient_loss | -0.0144      |
|    value_loss           | 0.149        |
------------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 36.1        |
|    ep_rew_mean          | 103         |
| time/                   |             |
|    fps                  | 693         |
|    iterations           | 15          |
|    time_elapsed         | 354         |
|    total_timesteps      | 245760      |
| train/                  |             |
|    approx_kl            | 0.007794289 |
|    clip_fraction        | 0.361       |
|    clip_range           | 0.1         |
|    entropy_loss         | -3.66       |
|    explained_variance   | 0.827       |
|    learning_rate        | 0.0003      |
|    loss                 | -0.0365     |
|    n_updates            | 112         |
|    policy_gradient_loss | -0.0149     |
|    value_loss           | 0.146       |
-----------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 36.5         |
|    ep_rew_mean          | 98.8         |
| time/                   |              |
|    fps                  | 687          |
|    iterations           | 16           |
|    time_elapsed         | 381          |
|    total_timesteps      | 262144       |
| train/                  |              |
|    approx_kl            | 0.0075348574 |
|    clip_fraction        | 0.371        |
|    clip_range           | 0.1          |
|    entropy_loss         | -3.65        |
|    explained_variance   | 0.823        |
|    learning_rate        | 0.0003       |
|    loss                 | -0.0267      |
|    n_updates            | 120          |
|    policy_gradient_loss | -0.0149      |
|    value_loss           | 0.155        |
------------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 36.6        |
|    ep_rew_mean          | 99.2        |
| time/                   |             |
|    fps                  | 679         |
|    iterations           | 17          |
|    time_elapsed         | 410         |
|    total_timesteps      | 278528      |
| train/                  |             |
|    approx_kl            | 0.007862521 |
|    clip_fraction        | 0.375       |
|    clip_range           | 0.1         |
|    entropy_loss         | -3.65       |
|    explained_variance   | 0.836       |
|    learning_rate        | 0.0003      |
|    loss                 | -0.0289     |
|    n_updates            | 128         |
|    policy_gradient_loss | -0.0146     |
|    value_loss           | 0.144       |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 36.4        |
|    ep_rew_mean          | 100         |
| time/                   |             |
|    fps                  | 676         |
|    iterations           | 18          |
|    time_elapsed         | 435         |
|    total_timesteps      | 294912      |
| train/                  |             |
|    approx_kl            | 0.008147977 |
|    clip_fraction        | 0.376       |
|    clip_range           | 0.1         |
|    entropy_loss         | -3.64       |
|    explained_variance   | 0.82        |
|    learning_rate        | 0.0003      |
|    loss                 | -0.0519     |
|    n_updates            | 136         |
|    policy_gradient_loss | -0.0148     |
|    value_loss           | 0.15        |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 36.5        |
|    ep_rew_mean          | 102         |
| time/                   |             |
|    fps                  | 677         |
|    iterations           | 19          |
|    time_elapsed         | 459         |
|    total_timesteps      | 311296      |
| train/                  |             |
|    approx_kl            | 0.008595729 |
|    clip_fraction        | 0.39        |
|    clip_range           | 0.1         |
|    entropy_loss         | -3.63       |
|    explained_variance   | 0.839       |
|    learning_rate        | 0.0003      |
|    loss                 | -0.0309     |
|    n_updates            | 144         |
|    policy_gradient_loss | -0.0157     |
|    value_loss           | 0.126       |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 36.9        |
|    ep_rew_mean          | 101         |
| time/                   |             |
|    fps                  | 677         |
|    iterations           | 20          |
|    time_elapsed         | 483         |
|    total_timesteps      | 327680      |
| train/                  |             |
|    approx_kl            | 0.008797234 |
|    clip_fraction        | 0.392       |
|    clip_range           | 0.1         |
|    entropy_loss         | -3.62       |
|    explained_variance   | 0.832       |
|    learning_rate        | 0.0003      |
|    loss                 | -0.047      |
|    n_updates            | 152         |
|    policy_gradient_loss | -0.0158     |
|    value_loss           | 0.138       |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 36.8        |
|    ep_rew_mean          | 108         |
| time/                   |             |
|    fps                  | 676         |
|    iterations           | 21          |
|    time_elapsed         | 508         |
|    total_timesteps      | 344064      |
| train/                  |             |
|    approx_kl            | 0.009170584 |
|    clip_fraction        | 0.403       |
|    clip_range           | 0.1         |
|    entropy_loss         | -3.61       |
|    explained_variance   | 0.832       |
|    learning_rate        | 0.0003      |
|    loss                 | -0.0294     |
|    n_updates            | 160         |
|    policy_gradient_loss | -0.017      |
|    value_loss           | 0.143       |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 36.6        |
|    ep_rew_mean          | 97.7        |
| time/                   |             |
|    fps                  | 670         |
|    iterations           | 22          |
|    time_elapsed         | 537         |
|    total_timesteps      | 360448      |
| train/                  |             |
|    approx_kl            | 0.009375476 |
|    clip_fraction        | 0.403       |
|    clip_range           | 0.1         |
|    entropy_loss         | -3.6        |
|    explained_variance   | 0.836       |
|    learning_rate        | 0.0003      |
|    loss                 | -0.0198     |
|    n_updates            | 168         |
|    policy_gradient_loss | -0.0167     |
|    value_loss           | 0.137       |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 36.8        |
|    ep_rew_mean          | 105         |
| time/                   |             |
|    fps                  | 673         |
|    iterations           | 23          |
|    time_elapsed         | 559         |
|    total_timesteps      | 376832      |
| train/                  |             |
|    approx_kl            | 0.009840554 |
|    clip_fraction        | 0.416       |
|    clip_range           | 0.1         |
|    entropy_loss         | -3.59       |
|    explained_variance   | 0.838       |
|    learning_rate        | 0.0003      |
|    loss                 | -0.028      |
|    n_updates            | 176         |
|    policy_gradient_loss | -0.0176     |
|    value_loss           | 0.133       |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 37         |
|    ep_rew_mean          | 105        |
| time/                   |            |
|    fps                  | 674        |
|    iterations           | 24         |
|    time_elapsed         | 583        |
|    total_timesteps      | 393216     |
| train/                  |            |
|    approx_kl            | 0.00982339 |
|    clip_fraction        | 0.414      |
|    clip_range           | 0.1        |
|    entropy_loss         | -3.58      |
|    explained_variance   | 0.813      |
|    learning_rate        | 0.0003     |
|    loss                 | -0.0374    |
|    n_updates            | 184        |
|    policy_gradient_loss | -0.0169    |
|    value_loss           | 0.153      |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 37.1        |
|    ep_rew_mean          | 106         |
| time/                   |             |
|    fps                  | 675         |
|    iterations           | 25          |
|    time_elapsed         | 606         |
|    total_timesteps      | 409600      |
| train/                  |             |
|    approx_kl            | 0.010144227 |
|    clip_fraction        | 0.419       |
|    clip_range           | 0.1         |
|    entropy_loss         | -3.57       |
|    explained_variance   | 0.816       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.0379      |
|    n_updates            | 192         |
|    policy_gradient_loss | -0.018      |
|    value_loss           | 0.148       |
-----------------------------------------
INFO:train_ppo_vecnorm:Entrenando PPO Fase 2 por 400000 timesteps...
Using cpu device
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 37.2     |
|    ep_rew_mean     | 107      |
| time/              |          |
|    fps             | 1733     |
|    iterations      | 1        |
|    time_elapsed    | 18       |
|    total_timesteps | 32768    |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 36.9        |
|    ep_rew_mean          | 106         |
| time/                   |             |
|    fps                  | 907         |
|    iterations           | 2           |
|    time_elapsed         | 72          |
|    total_timesteps      | 65536       |
| train/                  |             |
|    approx_kl            | 0.010605987 |
|    clip_fraction        | 0.432       |
|    clip_range           | 0.1         |
|    entropy_loss         | -3.55       |
|    explained_variance   | 0.838       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.00537     |
|    n_updates            | 8           |
|    policy_gradient_loss | -0.0109     |
|    value_loss           | 0.134       |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 37.1       |
|    ep_rew_mean          | 99.7       |
| time/                   |            |
|    fps                  | 784        |
|    iterations           | 3          |
|    time_elapsed         | 125        |
|    total_timesteps      | 98304      |
| train/                  |            |
|    approx_kl            | 0.01088149 |
|    clip_fraction        | 0.431      |
|    clip_range           | 0.1        |
|    entropy_loss         | -3.54      |
|    explained_variance   | 0.85       |
|    learning_rate        | 0.0003     |
|    loss                 | 0.0015     |
|    n_updates            | 16         |
|    policy_gradient_loss | -0.0108    |
|    value_loss           | 0.133      |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 37.1        |
|    ep_rew_mean          | 108         |
| time/                   |             |
|    fps                  | 744         |
|    iterations           | 4           |
|    time_elapsed         | 176         |
|    total_timesteps      | 131072      |
| train/                  |             |
|    approx_kl            | 0.011218571 |
|    clip_fraction        | 0.436       |
|    clip_range           | 0.1         |
|    entropy_loss         | -3.53       |
|    explained_variance   | 0.852       |
|    learning_rate        | 0.0003      |
|    loss                 | -0.00673    |
|    n_updates            | 24          |
|    policy_gradient_loss | -0.011      |
|    value_loss           | 0.13        |
-----------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 37.4         |
|    ep_rew_mean          | 104          |
| time/                   |              |
|    fps                  | 721          |
|    iterations           | 5            |
|    time_elapsed         | 227          |
|    total_timesteps      | 163840       |
| train/                  |              |
|    approx_kl            | 0.0116874315 |
|    clip_fraction        | 0.443        |
|    clip_range           | 0.1          |
|    entropy_loss         | -3.52        |
|    explained_variance   | 0.841        |
|    learning_rate        | 0.0003       |
|    loss                 | 0.0179       |
|    n_updates            | 32           |
|    policy_gradient_loss | -0.0114      |
|    value_loss           | 0.14         |
------------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 37.3        |
|    ep_rew_mean          | 106         |
| time/                   |             |
|    fps                  | 710         |
|    iterations           | 6           |
|    time_elapsed         | 276         |
|    total_timesteps      | 196608      |
| train/                  |             |
|    approx_kl            | 0.011815988 |
|    clip_fraction        | 0.447       |
|    clip_range           | 0.1         |
|    entropy_loss         | -3.51       |
|    explained_variance   | 0.844       |
|    learning_rate        | 0.0003      |
|    loss                 | -0.00799    |
|    n_updates            | 40          |
|    policy_gradient_loss | -0.0116     |
|    value_loss           | 0.136       |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 37.4        |
|    ep_rew_mean          | 111         |
| time/                   |             |
|    fps                  | 701         |
|    iterations           | 7           |
|    time_elapsed         | 326         |
|    total_timesteps      | 229376      |
| train/                  |             |
|    approx_kl            | 0.012155669 |
|    clip_fraction        | 0.448       |
|    clip_range           | 0.1         |
|    entropy_loss         | -3.5        |
|    explained_variance   | 0.847       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.0217      |
|    n_updates            | 48          |
|    policy_gradient_loss | -0.0118     |
|    value_loss           | 0.135       |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 37.8        |
|    ep_rew_mean          | 104         |
| time/                   |             |
|    fps                  | 697         |
|    iterations           | 8           |
|    time_elapsed         | 375         |
|    total_timesteps      | 262144      |
| train/                  |             |
|    approx_kl            | 0.012795257 |
|    clip_fraction        | 0.464       |
|    clip_range           | 0.1         |
|    entropy_loss         | -3.49       |
|    explained_variance   | 0.841       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.00263     |
|    n_updates            | 56          |
|    policy_gradient_loss | -0.0125     |
|    value_loss           | 0.146       |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 37.5        |
|    ep_rew_mean          | 111         |
| time/                   |             |
|    fps                  | 695         |
|    iterations           | 9           |
|    time_elapsed         | 424         |
|    total_timesteps      | 294912      |
| train/                  |             |
|    approx_kl            | 0.012859158 |
|    clip_fraction        | 0.466       |
|    clip_range           | 0.1         |
|    entropy_loss         | -3.48       |
|    explained_variance   | 0.839       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.0198      |
|    n_updates            | 64          |
|    policy_gradient_loss | -0.0124     |
|    value_loss           | 0.135       |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 37.6        |
|    ep_rew_mean          | 107         |
| time/                   |             |
|    fps                  | 696         |
|    iterations           | 10          |
|    time_elapsed         | 470         |
|    total_timesteps      | 327680      |
| train/                  |             |
|    approx_kl            | 0.013209642 |
|    clip_fraction        | 0.47        |
|    clip_range           | 0.1         |
|    entropy_loss         | -3.47       |
|    explained_variance   | 0.845       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.0316      |
|    n_updates            | 72          |
|    policy_gradient_loss | -0.0129     |
|    value_loss           | 0.137       |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 37.6       |
|    ep_rew_mean          | 109        |
| time/                   |            |
|    fps                  | 697        |
|    iterations           | 11         |
|    time_elapsed         | 516        |
|    total_timesteps      | 360448     |
| train/                  |            |
|    approx_kl            | 0.01388163 |
|    clip_fraction        | 0.479      |
|    clip_range           | 0.1        |
|    entropy_loss         | -3.46      |
|    explained_variance   | 0.844      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.0098     |
|    n_updates            | 80         |
|    policy_gradient_loss | -0.013     |
|    value_loss           | 0.136      |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 37.7        |
|    ep_rew_mean          | 106         |
| time/                   |             |
|    fps                  | 699         |
|    iterations           | 12          |
|    time_elapsed         | 561         |
|    total_timesteps      | 393216      |
| train/                  |             |
|    approx_kl            | 0.013916798 |
|    clip_fraction        | 0.478       |
|    clip_range           | 0.1         |
|    entropy_loss         | -3.45       |
|    explained_variance   | 0.842       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.0133      |
|    n_updates            | 88          |
|    policy_gradient_loss | -0.013      |
|    value_loss           | 0.138       |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 37.5        |
|    ep_rew_mean          | 113         |
| time/                   |             |
|    fps                  | 697         |
|    iterations           | 13          |
|    time_elapsed         | 610         |
|    total_timesteps      | 425984      |
| train/                  |             |
|    approx_kl            | 0.014470719 |
|    clip_fraction        | 0.489       |
|    clip_range           | 0.1         |
|    entropy_loss         | -3.44       |
|    explained_variance   | 0.847       |
|    learning_rate        | 0.0003      |
|    loss                 | -0.0136     |
|    n_updates            | 96          |
|    policy_gradient_loss | -0.0137     |
|    value_loss           | 0.133       |
-----------------------------------------
INFO:train_ppo_vecnorm:Entrenando PPO Fase 3 por 300000 timesteps...
Using cpu device
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 37.7     |
|    ep_rew_mean     | 113      |
| time/              |          |
|    fps             | 1445     |
|    iterations      | 1        |
|    time_elapsed    | 34       |
|    total_timesteps | 49152    |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 37.7        |
|    ep_rew_mean          | 110         |
| time/                   |             |
|    fps                  | 904         |
|    iterations           | 2           |
|    time_elapsed         | 108         |
|    total_timesteps      | 98304       |
| train/                  |             |
|    approx_kl            | 0.014854475 |
|    clip_fraction        | 0.495       |
|    clip_range           | 0.1         |
|    entropy_loss         | -3.42       |
|    explained_variance   | 0.851       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.0164      |
|    n_updates            | 8           |
|    policy_gradient_loss | -0.00879    |
|    value_loss           | 0.133       |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 37.9        |
|    ep_rew_mean          | 109         |
| time/                   |             |
|    fps                  | 806         |
|    iterations           | 3           |
|    time_elapsed         | 182         |
|    total_timesteps      | 147456      |
| train/                  |             |
|    approx_kl            | 0.015316025 |
|    clip_fraction        | 0.501       |
|    clip_range           | 0.1         |
|    entropy_loss         | -3.4        |
|    explained_variance   | 0.847       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.062       |
|    n_updates            | 16          |
|    policy_gradient_loss | -0.00962    |
|    value_loss           | 0.137       |
-----------------------------------------
Early stopping at step 7 due to reaching max kl: 0.03
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 37.6        |
|    ep_rew_mean          | 108         |
| time/                   |             |
|    fps                  | 770         |
|    iterations           | 4           |
|    time_elapsed         | 255         |
|    total_timesteps      | 196608      |
| train/                  |             |
|    approx_kl            | 0.015158171 |
|    clip_fraction        | 0.498       |
|    clip_range           | 0.1         |
|    entropy_loss         | -3.38       |
|    explained_variance   | 0.843       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.0393      |
|    n_updates            | 24          |
|    policy_gradient_loss | -0.00842    |
|    value_loss           | 0.147       |
-----------------------------------------
Early stopping at step 6 due to reaching max kl: 0.03
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 37.6       |
|    ep_rew_mean          | 106        |
| time/                   |            |
|    fps                  | 769        |
|    iterations           | 5          |
|    time_elapsed         | 319        |
|    total_timesteps      | 245760     |
| train/                  |            |
|    approx_kl            | 0.01568322 |
|    clip_fraction        | 0.496      |
|    clip_range           | 0.1        |
|    entropy_loss         | -3.38      |
|    explained_variance   | 0.856      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.0315     |
|    n_updates            | 31         |
|    policy_gradient_loss | -0.00695   |
|    value_loss           | 0.135      |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 37.8        |
|    ep_rew_mean          | 107         |
| time/                   |             |
|    fps                  | 751         |
|    iterations           | 6           |
|    time_elapsed         | 392         |
|    total_timesteps      | 294912      |
| train/                  |             |
|    approx_kl            | 0.016385676 |
|    clip_fraction        | 0.511       |
|    clip_range           | 0.1         |
|    entropy_loss         | -3.36       |
|    explained_variance   | 0.852       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.0467      |
|    n_updates            | 39          |
|    policy_gradient_loss | -0.0097     |
|    value_loss           | 0.139       |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 37.5        |
|    ep_rew_mean          | 111         |
| time/                   |             |
|    fps                  | 725         |
|    iterations           | 7           |
|    time_elapsed         | 474         |
|    total_timesteps      | 344064      |
| train/                  |             |
|    approx_kl            | 0.016363857 |
|    clip_fraction        | 0.511       |
|    clip_range           | 0.1         |
|    entropy_loss         | -3.35       |
|    explained_variance   | 0.858       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.00964     |
|    n_updates            | 47          |
|    policy_gradient_loss | -0.00963    |
|    value_loss           | 0.132       |
-----------------------------------------
INFO:train_ppo_vecnorm:Modelo guardado en best/ppo_ablation/ppo_conservative_clip_kl/seed_126/best/ppo_yahtzee_vecnorm_final y estadisticas de normalizacion en best/ppo_ablation/ppo_conservative_clip_kl/seed_126/best/ppo_vecnorm_stats.pkl
INFO:final_evaluate_rl:Autodeteccion: modelo=best/ppo_ablation/ppo_conservative_clip_kl/seed_126/best/ppo_yahtzee_vecnorm_final, stats=best/ppo_ablation/ppo_conservative_clip_kl/seed_126/best/ppo_vecnorm_stats.pkl, algo=ppo
INFO:final_evaluate_rl:Cargando modelo: best/ppo_ablation/ppo_conservative_clip_kl/seed_126/best/ppo_yahtzee_vecnorm_final
INFO:final_evaluate_rl:Algo detectado/forzado: ppo
INFO:final_evaluate_rl:Evaluando el modelo con recompensas SIN normalizar(evaluacion segura)...
INFO:final_evaluate_rl:Episode 1: Recompensa del episodio: 127.33599952451186, Puntuacion final: 129.0
INFO:final_evaluate_rl:Episode 2: Recompensa del episodio: 129.11750089377165, Puntuacion final: 130.0
INFO:final_evaluate_rl:Episode 3: Recompensa del episodio: 70.12600009725429, Puntuacion final: 72.0
INFO:final_evaluate_rl:Episode 4: Recompensa del episodio: 116.2210019857157, Puntuacion final: 119.0
INFO:final_evaluate_rl:Episode 5: Recompensa del episodio: 103.16750015236903, Puntuacion final: 105.0
INFO:final_evaluate_rl:Episode 6: Recompensa del episodio: 119.80500127235427, Puntuacion final: 123.0
INFO:final_evaluate_rl:Episode 7: Recompensa del episodio: 116.96200261579361, Puntuacion final: 119.0
INFO:final_evaluate_rl:Episode 8: Recompensa del episodio: 168.51399870868772, Puntuacion final: 171.0
INFO:final_evaluate_rl:Episode 9: Recompensa del episodio: 133.1250001376029, Puntuacion final: 135.0
INFO:final_evaluate_rl:Episode 10: Recompensa del episodio: 130.33950009249384, Puntuacion final: 132.0
INFO:final_evaluate_rl:Episode 11: Recompensa del episodio: 109.05499872227665, Puntuacion final: 111.0
INFO:final_evaluate_rl:Episode 12: Recompensa del episodio: 123.65949958586134, Puntuacion final: 126.0
INFO:final_evaluate_rl:Episode 13: Recompensa del episodio: 115.20500087924302, Puntuacion final: 117.0
INFO:final_evaluate_rl:Episode 14: Recompensa del episodio: 112.92700010311091, Puntuacion final: 115.0
INFO:final_evaluate_rl:Episode 15: Recompensa del episodio: 123.02599807817023, Puntuacion final: 125.0
INFO:final_evaluate_rl:Episode 16: Recompensa del episodio: 97.68100057786796, Puntuacion final: 100.0
INFO:final_evaluate_rl:Episode 17: Recompensa del episodio: 120.84650104766479, Puntuacion final: 125.0
INFO:final_evaluate_rl:Episode 18: Recompensa del episodio: 71.35099913110025, Puntuacion final: 73.0
INFO:final_evaluate_rl:Episode 19: Recompensa del episodio: 91.28799971786793, Puntuacion final: 93.0
INFO:final_evaluate_rl:Episode 20: Recompensa del episodio: 127.42499996372499, Puntuacion final: 129.0
INFO:final_evaluate_rl:Episode 21: Recompensa del episodio: 108.96599941526074, Puntuacion final: 110.0
INFO:final_evaluate_rl:Episode 22: Recompensa del episodio: 136.26150301401503, Puntuacion final: 138.0
INFO:final_evaluate_rl:Episode 23: Recompensa del episodio: 51.07800012594089, Puntuacion final: 53.0
INFO:final_evaluate_rl:Episode 24: Recompensa del episodio: 134.27350072655827, Puntuacion final: 136.0
INFO:final_evaluate_rl:Episode 25: Recompensa del episodio: 92.87700146227144, Puntuacion final: 96.0
INFO:final_evaluate_rl:Episode 26: Recompensa del episodio: 86.34400093887234, Puntuacion final: 89.0
INFO:final_evaluate_rl:Episode 27: Recompensa del episodio: 193.79249955317937, Puntuacion final: 198.0
INFO:final_evaluate_rl:Episode 28: Recompensa del episodio: 138.24550111801364, Puntuacion final: 140.0
INFO:final_evaluate_rl:Episode 29: Recompensa del episodio: 133.03850027779117, Puntuacion final: 135.0
INFO:final_evaluate_rl:Episode 30: Recompensa del episodio: 83.84500040276907, Puntuacion final: 87.0
INFO:final_evaluate_rl:Episode 31: Recompensa del episodio: 122.65499920281582, Puntuacion final: 124.0
INFO:final_evaluate_rl:Episode 32: Recompensa del episodio: 126.92899948125705, Puntuacion final: 129.0
INFO:final_evaluate_rl:Episode 33: Recompensa del episodio: 140.8319991179742, Puntuacion final: 145.0
INFO:final_evaluate_rl:Episode 34: Recompensa del episodio: 168.21599851851352, Puntuacion final: 170.0
INFO:final_evaluate_rl:Episode 35: Recompensa del episodio: 97.86900008784141, Puntuacion final: 102.0
INFO:final_evaluate_rl:Episode 36: Recompensa del episodio: 113.14449743006844, Puntuacion final: 115.0
INFO:final_evaluate_rl:Episode 37: Recompensa del episodio: 129.42750042612897, Puntuacion final: 131.0
INFO:final_evaluate_rl:Episode 38: Recompensa del episodio: 72.80550101632252, Puntuacion final: 75.0
INFO:final_evaluate_rl:Episode 39: Recompensa del episodio: 116.67850033892319, Puntuacion final: 119.0
INFO:final_evaluate_rl:Episode 40: Recompensa del episodio: 105.65199991036206, Puntuacion final: 108.0
INFO:final_evaluate_rl:Episode 41: Recompensa del episodio: 134.30300044827163, Puntuacion final: 136.0
INFO:final_evaluate_rl:Episode 42: Recompensa del episodio: 119.32300034211949, Puntuacion final: 121.0
INFO:final_evaluate_rl:Episode 43: Recompensa del episodio: 116.8310015425086, Puntuacion final: 120.0
INFO:final_evaluate_rl:Episode 44: Recompensa del episodio: 120.14499936357606, Puntuacion final: 122.0
INFO:final_evaluate_rl:Episode 45: Recompensa del episodio: 138.77699936623685, Puntuacion final: 142.0
INFO:final_evaluate_rl:Episode 46: Recompensa del episodio: 115.77949966676533, Puntuacion final: 120.0
INFO:final_evaluate_rl:Episode 47: Recompensa del episodio: 108.83949976612348, Puntuacion final: 111.0
INFO:final_evaluate_rl:Episode 48: Recompensa del episodio: 90.28499983344227, Puntuacion final: 92.0
INFO:final_evaluate_rl:Episode 49: Recompensa del episodio: 138.72100078919902, Puntuacion final: 140.0
INFO:final_evaluate_rl:Episode 50: Recompensa del episodio: 145.45949916081736, Puntuacion final: 147.0
INFO:final_evaluate_rl:Metricas guardadas en ppo_vecnorm_final_evaluation_metrics.txt
Early stopping at step 7 due to reaching max kl: 0.04
Grafica guardada en best/ppo_ablation/ppo_conservative_clip_kl/seed_126/best/ppo_vecnorm_reward_evolution.png

Resumen:
  Recompensa media (sin normalizar): 117.7714
  Puntuacion final promedio:        120.0000
