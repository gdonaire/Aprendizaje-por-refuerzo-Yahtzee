INFO:train_ppo_vecnorm:Creando 8 entornos paralelos con VecNormalize...
INFO:train_ppo_vecnorm:Activando wrapper de reparacion de acciones invalidas durante TRAINING...
INFO:train_ppo_vecnorm:Aplicando VecNormalize (obs y reward normalizados)...
INFO:train_ppo_vecnorm:Entrenando PPO Fase 1 por 400000 timesteps...
Argumentos de entrenamiento:
  timesteps: 400000
  timesteps2: 400000
  timesteps3: 300000
  n_envs: 8
  seed: 126
  lr: 0.0003
  n_steps: 2048
  batch_size: 64
  n_epochs: 10
  gamma: 0.99
  gae_lambda: 0.95
  ent_coef: 0.02
  clip_range: 0.2
  vf_coef: 0.5
  max_grad_norm: 0.5
  target_kl: None
  use_sde: False
  sde_sample_freq: -1
  policy_arch: {"pi":[256, 256], "vf":[256, 256]}
  eval_episodes: 50
  best_dir: best/ppo_ablation/ppo_baseline/seed_126/best
  plot_ma_long: 200
  repair_actions_training: True
Using cpu device
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 32.8     |
|    ep_rew_mean     | 76.1     |
| time/              |          |
|    fps             | 2023     |
|    iterations      | 1        |
|    time_elapsed    | 8        |
|    total_timesteps | 16384    |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 33.6       |
|    ep_rew_mean          | 78.6       |
| time/                   |            |
|    fps                  | 1039       |
|    iterations           | 2          |
|    time_elapsed         | 31         |
|    total_timesteps      | 32768      |
| train/                  |            |
|    approx_kl            | 0.02263108 |
|    clip_fraction        | 0.243      |
|    clip_range           | 0.2        |
|    entropy_loss         | -3.77      |
|    explained_variance   | 0.15       |
|    learning_rate        | 0.0003     |
|    loss                 | 0.0153     |
|    n_updates            | 10         |
|    policy_gradient_loss | -0.0218    |
|    value_loss           | 0.234      |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 33.8        |
|    ep_rew_mean          | 86.2        |
| time/                   |             |
|    fps                  | 904         |
|    iterations           | 3           |
|    time_elapsed         | 54          |
|    total_timesteps      | 49152       |
| train/                  |             |
|    approx_kl            | 0.021457732 |
|    clip_fraction        | 0.265       |
|    clip_range           | 0.2         |
|    entropy_loss         | -3.74       |
|    explained_variance   | 0.663       |
|    learning_rate        | 0.0003      |
|    loss                 | -0.032      |
|    n_updates            | 20          |
|    policy_gradient_loss | -0.0246     |
|    value_loss           | 0.177       |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 34.8        |
|    ep_rew_mean          | 90.3        |
| time/                   |             |
|    fps                  | 852         |
|    iterations           | 4           |
|    time_elapsed         | 76          |
|    total_timesteps      | 65536       |
| train/                  |             |
|    approx_kl            | 0.018830847 |
|    clip_fraction        | 0.27        |
|    clip_range           | 0.2         |
|    entropy_loss         | -3.72       |
|    explained_variance   | 0.754       |
|    learning_rate        | 0.0003      |
|    loss                 | -0.0369     |
|    n_updates            | 30          |
|    policy_gradient_loss | -0.0268     |
|    value_loss           | 0.184       |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 34.7        |
|    ep_rew_mean          | 90.9        |
| time/                   |             |
|    fps                  | 825         |
|    iterations           | 5           |
|    time_elapsed         | 99          |
|    total_timesteps      | 81920       |
| train/                  |             |
|    approx_kl            | 0.018876117 |
|    clip_fraction        | 0.27        |
|    clip_range           | 0.2         |
|    entropy_loss         | -3.68       |
|    explained_variance   | 0.782       |
|    learning_rate        | 0.0003      |
|    loss                 | -0.0301     |
|    n_updates            | 40          |
|    policy_gradient_loss | -0.029      |
|    value_loss           | 0.18        |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 35.5        |
|    ep_rew_mean          | 97.9        |
| time/                   |             |
|    fps                  | 801         |
|    iterations           | 6           |
|    time_elapsed         | 122         |
|    total_timesteps      | 98304       |
| train/                  |             |
|    approx_kl            | 0.018911969 |
|    clip_fraction        | 0.275       |
|    clip_range           | 0.2         |
|    entropy_loss         | -3.66       |
|    explained_variance   | 0.818       |
|    learning_rate        | 0.0003      |
|    loss                 | -0.0619     |
|    n_updates            | 50          |
|    policy_gradient_loss | -0.0313     |
|    value_loss           | 0.153       |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 35.8        |
|    ep_rew_mean          | 102         |
| time/                   |             |
|    fps                  | 790         |
|    iterations           | 7           |
|    time_elapsed         | 145         |
|    total_timesteps      | 114688      |
| train/                  |             |
|    approx_kl            | 0.019834094 |
|    clip_fraction        | 0.278       |
|    clip_range           | 0.2         |
|    entropy_loss         | -3.63       |
|    explained_variance   | 0.811       |
|    learning_rate        | 0.0003      |
|    loss                 | -0.0528     |
|    n_updates            | 60          |
|    policy_gradient_loss | -0.0347     |
|    value_loss           | 0.159       |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 35.9        |
|    ep_rew_mean          | 98.1        |
| time/                   |             |
|    fps                  | 780         |
|    iterations           | 8           |
|    time_elapsed         | 168         |
|    total_timesteps      | 131072      |
| train/                  |             |
|    approx_kl            | 0.021735191 |
|    clip_fraction        | 0.293       |
|    clip_range           | 0.2         |
|    entropy_loss         | -3.6        |
|    explained_variance   | 0.81        |
|    learning_rate        | 0.0003      |
|    loss                 | -0.0511     |
|    n_updates            | 70          |
|    policy_gradient_loss | -0.0387     |
|    value_loss           | 0.163       |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 36.3        |
|    ep_rew_mean          | 99.6        |
| time/                   |             |
|    fps                  | 768         |
|    iterations           | 9           |
|    time_elapsed         | 191         |
|    total_timesteps      | 147456      |
| train/                  |             |
|    approx_kl            | 0.022230972 |
|    clip_fraction        | 0.292       |
|    clip_range           | 0.2         |
|    entropy_loss         | -3.58       |
|    explained_variance   | 0.816       |
|    learning_rate        | 0.0003      |
|    loss                 | -0.0796     |
|    n_updates            | 80          |
|    policy_gradient_loss | -0.0404     |
|    value_loss           | 0.149       |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 35.9        |
|    ep_rew_mean          | 101         |
| time/                   |             |
|    fps                  | 715         |
|    iterations           | 10          |
|    time_elapsed         | 229         |
|    total_timesteps      | 163840      |
| train/                  |             |
|    approx_kl            | 0.023304388 |
|    clip_fraction        | 0.301       |
|    clip_range           | 0.2         |
|    entropy_loss         | -3.56       |
|    explained_variance   | 0.797       |
|    learning_rate        | 0.0003      |
|    loss                 | -0.0677     |
|    n_updates            | 90          |
|    policy_gradient_loss | -0.043      |
|    value_loss           | 0.154       |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 36.9        |
|    ep_rew_mean          | 109         |
| time/                   |             |
|    fps                  | 703         |
|    iterations           | 11          |
|    time_elapsed         | 256         |
|    total_timesteps      | 180224      |
| train/                  |             |
|    approx_kl            | 0.026004896 |
|    clip_fraction        | 0.324       |
|    clip_range           | 0.2         |
|    entropy_loss         | -3.53       |
|    explained_variance   | 0.828       |
|    learning_rate        | 0.0003      |
|    loss                 | -0.107      |
|    n_updates            | 100         |
|    policy_gradient_loss | -0.0477     |
|    value_loss           | 0.135       |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 36.5        |
|    ep_rew_mean          | 103         |
| time/                   |             |
|    fps                  | 694         |
|    iterations           | 12          |
|    time_elapsed         | 282         |
|    total_timesteps      | 196608      |
| train/                  |             |
|    approx_kl            | 0.026134126 |
|    clip_fraction        | 0.319       |
|    clip_range           | 0.2         |
|    entropy_loss         | -3.51       |
|    explained_variance   | 0.837       |
|    learning_rate        | 0.0003      |
|    loss                 | -0.109      |
|    n_updates            | 110         |
|    policy_gradient_loss | -0.0474     |
|    value_loss           | 0.128       |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 36.6        |
|    ep_rew_mean          | 107         |
| time/                   |             |
|    fps                  | 686         |
|    iterations           | 13          |
|    time_elapsed         | 310         |
|    total_timesteps      | 212992      |
| train/                  |             |
|    approx_kl            | 0.027789708 |
|    clip_fraction        | 0.328       |
|    clip_range           | 0.2         |
|    entropy_loss         | -3.49       |
|    explained_variance   | 0.848       |
|    learning_rate        | 0.0003      |
|    loss                 | -0.0833     |
|    n_updates            | 120         |
|    policy_gradient_loss | -0.0492     |
|    value_loss           | 0.119       |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 36.8        |
|    ep_rew_mean          | 103         |
| time/                   |             |
|    fps                  | 680         |
|    iterations           | 14          |
|    time_elapsed         | 336         |
|    total_timesteps      | 229376      |
| train/                  |             |
|    approx_kl            | 0.028155942 |
|    clip_fraction        | 0.337       |
|    clip_range           | 0.2         |
|    entropy_loss         | -3.47       |
|    explained_variance   | 0.833       |
|    learning_rate        | 0.0003      |
|    loss                 | -0.128      |
|    n_updates            | 130         |
|    policy_gradient_loss | -0.0508     |
|    value_loss           | 0.125       |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 36.8        |
|    ep_rew_mean          | 109         |
| time/                   |             |
|    fps                  | 675         |
|    iterations           | 15          |
|    time_elapsed         | 363         |
|    total_timesteps      | 245760      |
| train/                  |             |
|    approx_kl            | 0.029443901 |
|    clip_fraction        | 0.341       |
|    clip_range           | 0.2         |
|    entropy_loss         | -3.45       |
|    explained_variance   | 0.845       |
|    learning_rate        | 0.0003      |
|    loss                 | -0.126      |
|    n_updates            | 140         |
|    policy_gradient_loss | -0.0514     |
|    value_loss           | 0.122       |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 36.9        |
|    ep_rew_mean          | 106         |
| time/                   |             |
|    fps                  | 671         |
|    iterations           | 16          |
|    time_elapsed         | 390         |
|    total_timesteps      | 262144      |
| train/                  |             |
|    approx_kl            | 0.031432707 |
|    clip_fraction        | 0.356       |
|    clip_range           | 0.2         |
|    entropy_loss         | -3.43       |
|    explained_variance   | 0.837       |
|    learning_rate        | 0.0003      |
|    loss                 | -0.121      |
|    n_updates            | 150         |
|    policy_gradient_loss | -0.0556     |
|    value_loss           | 0.124       |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 36.9       |
|    ep_rew_mean          | 105        |
| time/                   |            |
|    fps                  | 669        |
|    iterations           | 17         |
|    time_elapsed         | 416        |
|    total_timesteps      | 278528     |
| train/                  |            |
|    approx_kl            | 0.03218863 |
|    clip_fraction        | 0.358      |
|    clip_range           | 0.2        |
|    entropy_loss         | -3.41      |
|    explained_variance   | 0.823      |
|    learning_rate        | 0.0003     |
|    loss                 | -0.0872    |
|    n_updates            | 160        |
|    policy_gradient_loss | -0.0566    |
|    value_loss           | 0.125      |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 36.9        |
|    ep_rew_mean          | 104         |
| time/                   |             |
|    fps                  | 666         |
|    iterations           | 18          |
|    time_elapsed         | 442         |
|    total_timesteps      | 294912      |
| train/                  |             |
|    approx_kl            | 0.033434883 |
|    clip_fraction        | 0.374       |
|    clip_range           | 0.2         |
|    entropy_loss         | -3.39       |
|    explained_variance   | 0.832       |
|    learning_rate        | 0.0003      |
|    loss                 | -0.108      |
|    n_updates            | 170         |
|    policy_gradient_loss | -0.0592     |
|    value_loss           | 0.128       |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 37          |
|    ep_rew_mean          | 102         |
| time/                   |             |
|    fps                  | 659         |
|    iterations           | 19          |
|    time_elapsed         | 472         |
|    total_timesteps      | 311296      |
| train/                  |             |
|    approx_kl            | 0.035491727 |
|    clip_fraction        | 0.379       |
|    clip_range           | 0.2         |
|    entropy_loss         | -3.38       |
|    explained_variance   | 0.838       |
|    learning_rate        | 0.0003      |
|    loss                 | -0.0997     |
|    n_updates            | 180         |
|    policy_gradient_loss | -0.0607     |
|    value_loss           | 0.12        |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 36.9        |
|    ep_rew_mean          | 104         |
| time/                   |             |
|    fps                  | 656         |
|    iterations           | 20          |
|    time_elapsed         | 499         |
|    total_timesteps      | 327680      |
| train/                  |             |
|    approx_kl            | 0.035371125 |
|    clip_fraction        | 0.385       |
|    clip_range           | 0.2         |
|    entropy_loss         | -3.36       |
|    explained_variance   | 0.832       |
|    learning_rate        | 0.0003      |
|    loss                 | -0.105      |
|    n_updates            | 190         |
|    policy_gradient_loss | -0.0615     |
|    value_loss           | 0.123       |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 37.2       |
|    ep_rew_mean          | 111        |
| time/                   |            |
|    fps                  | 652        |
|    iterations           | 21         |
|    time_elapsed         | 526        |
|    total_timesteps      | 344064     |
| train/                  |            |
|    approx_kl            | 0.03742937 |
|    clip_fraction        | 0.389      |
|    clip_range           | 0.2        |
|    entropy_loss         | -3.34      |
|    explained_variance   | 0.832      |
|    learning_rate        | 0.0003     |
|    loss                 | -0.102     |
|    n_updates            | 200        |
|    policy_gradient_loss | -0.0631    |
|    value_loss           | 0.119      |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 37.2       |
|    ep_rew_mean          | 104        |
| time/                   |            |
|    fps                  | 652        |
|    iterations           | 22         |
|    time_elapsed         | 552        |
|    total_timesteps      | 360448     |
| train/                  |            |
|    approx_kl            | 0.03808473 |
|    clip_fraction        | 0.397      |
|    clip_range           | 0.2        |
|    entropy_loss         | -3.33      |
|    explained_variance   | 0.834      |
|    learning_rate        | 0.0003     |
|    loss                 | -0.124     |
|    n_updates            | 210        |
|    policy_gradient_loss | -0.064     |
|    value_loss           | 0.119      |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 37.5       |
|    ep_rew_mean          | 109        |
| time/                   |            |
|    fps                  | 654        |
|    iterations           | 23         |
|    time_elapsed         | 575        |
|    total_timesteps      | 376832     |
| train/                  |            |
|    approx_kl            | 0.03905657 |
|    clip_fraction        | 0.399      |
|    clip_range           | 0.2        |
|    entropy_loss         | -3.31      |
|    explained_variance   | 0.829      |
|    learning_rate        | 0.0003     |
|    loss                 | -0.094     |
|    n_updates            | 220        |
|    policy_gradient_loss | -0.0636    |
|    value_loss           | 0.123      |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 37.6        |
|    ep_rew_mean          | 106         |
| time/                   |             |
|    fps                  | 657         |
|    iterations           | 24          |
|    time_elapsed         | 598         |
|    total_timesteps      | 393216      |
| train/                  |             |
|    approx_kl            | 0.041173007 |
|    clip_fraction        | 0.411       |
|    clip_range           | 0.2         |
|    entropy_loss         | -3.29       |
|    explained_variance   | 0.835       |
|    learning_rate        | 0.0003      |
|    loss                 | -0.119      |
|    n_updates            | 230         |
|    policy_gradient_loss | -0.0664     |
|    value_loss           | 0.123       |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 37.4        |
|    ep_rew_mean          | 111         |
| time/                   |             |
|    fps                  | 659         |
|    iterations           | 25          |
|    time_elapsed         | 621         |
|    total_timesteps      | 409600      |
| train/                  |             |
|    approx_kl            | 0.041967455 |
|    clip_fraction        | 0.417       |
|    clip_range           | 0.2         |
|    entropy_loss         | -3.27       |
|    explained_variance   | 0.836       |
|    learning_rate        | 0.0003      |
|    loss                 | -0.119      |
|    n_updates            | 240         |
|    policy_gradient_loss | -0.067      |
|    value_loss           | 0.116       |
-----------------------------------------
INFO:train_ppo_vecnorm:Entrenando PPO Fase 2 por 400000 timesteps...
Using cpu device
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 37.7     |
|    ep_rew_mean     | 108      |
| time/              |          |
|    fps             | 2004     |
|    iterations      | 1        |
|    time_elapsed    | 16       |
|    total_timesteps | 32768    |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 37.5        |
|    ep_rew_mean          | 112         |
| time/                   |             |
|    fps                  | 1065        |
|    iterations           | 2           |
|    time_elapsed         | 61          |
|    total_timesteps      | 65536       |
| train/                  |             |
|    approx_kl            | 0.043384604 |
|    clip_fraction        | 0.42        |
|    clip_range           | 0.2         |
|    entropy_loss         | -3.23       |
|    explained_variance   | 0.835       |
|    learning_rate        | 0.0003      |
|    loss                 | -0.0282     |
|    n_updates            | 10          |
|    policy_gradient_loss | -0.0513     |
|    value_loss           | 0.13        |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 37.5        |
|    ep_rew_mean          | 109         |
| time/                   |             |
|    fps                  | 916         |
|    iterations           | 3           |
|    time_elapsed         | 107         |
|    total_timesteps      | 98304       |
| train/                  |             |
|    approx_kl            | 0.044733718 |
|    clip_fraction        | 0.424       |
|    clip_range           | 0.2         |
|    entropy_loss         | -3.19       |
|    explained_variance   | 0.839       |
|    learning_rate        | 0.0003      |
|    loss                 | -0.0304     |
|    n_updates            | 20          |
|    policy_gradient_loss | -0.0519     |
|    value_loss           | 0.125       |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 37.4       |
|    ep_rew_mean          | 112        |
| time/                   |            |
|    fps                  | 858        |
|    iterations           | 4          |
|    time_elapsed         | 152        |
|    total_timesteps      | 131072     |
| train/                  |            |
|    approx_kl            | 0.04567822 |
|    clip_fraction        | 0.426      |
|    clip_range           | 0.2        |
|    entropy_loss         | -3.16      |
|    explained_variance   | 0.844      |
|    learning_rate        | 0.0003     |
|    loss                 | -0.0401    |
|    n_updates            | 30         |
|    policy_gradient_loss | -0.0516    |
|    value_loss           | 0.12       |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 37.7       |
|    ep_rew_mean          | 110        |
| time/                   |            |
|    fps                  | 818        |
|    iterations           | 5          |
|    time_elapsed         | 200        |
|    total_timesteps      | 163840     |
| train/                  |            |
|    approx_kl            | 0.04678127 |
|    clip_fraction        | 0.434      |
|    clip_range           | 0.2        |
|    entropy_loss         | -3.14      |
|    explained_variance   | 0.848      |
|    learning_rate        | 0.0003     |
|    loss                 | -0.0462    |
|    n_updates            | 40         |
|    policy_gradient_loss | -0.0526    |
|    value_loss           | 0.124      |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 37.6       |
|    ep_rew_mean          | 113        |
| time/                   |            |
|    fps                  | 802        |
|    iterations           | 6          |
|    time_elapsed         | 245        |
|    total_timesteps      | 196608     |
| train/                  |            |
|    approx_kl            | 0.04827279 |
|    clip_fraction        | 0.439      |
|    clip_range           | 0.2        |
|    entropy_loss         | -3.11      |
|    explained_variance   | 0.844      |
|    learning_rate        | 0.0003     |
|    loss                 | -0.0805    |
|    n_updates            | 50         |
|    policy_gradient_loss | -0.0536    |
|    value_loss           | 0.129      |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 37.5        |
|    ep_rew_mean          | 111         |
| time/                   |             |
|    fps                  | 790         |
|    iterations           | 7           |
|    time_elapsed         | 290         |
|    total_timesteps      | 229376      |
| train/                  |             |
|    approx_kl            | 0.049026184 |
|    clip_fraction        | 0.443       |
|    clip_range           | 0.2         |
|    entropy_loss         | -3.08       |
|    explained_variance   | 0.848       |
|    learning_rate        | 0.0003      |
|    loss                 | -0.0585     |
|    n_updates            | 60          |
|    policy_gradient_loss | -0.0541     |
|    value_loss           | 0.12        |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 37.6        |
|    ep_rew_mean          | 112         |
| time/                   |             |
|    fps                  | 780         |
|    iterations           | 8           |
|    time_elapsed         | 335         |
|    total_timesteps      | 262144      |
| train/                  |             |
|    approx_kl            | 0.049630724 |
|    clip_fraction        | 0.448       |
|    clip_range           | 0.2         |
|    entropy_loss         | -3.05       |
|    explained_variance   | 0.853       |
|    learning_rate        | 0.0003      |
|    loss                 | -0.0411     |
|    n_updates            | 70          |
|    policy_gradient_loss | -0.0541     |
|    value_loss           | 0.116       |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 37.5        |
|    ep_rew_mean          | 110         |
| time/                   |             |
|    fps                  | 773         |
|    iterations           | 9           |
|    time_elapsed         | 381         |
|    total_timesteps      | 294912      |
| train/                  |             |
|    approx_kl            | 0.051106513 |
|    clip_fraction        | 0.447       |
|    clip_range           | 0.2         |
|    entropy_loss         | -3.03       |
|    explained_variance   | 0.851       |
|    learning_rate        | 0.0003      |
|    loss                 | -0.0464     |
|    n_updates            | 80          |
|    policy_gradient_loss | -0.0547     |
|    value_loss           | 0.119       |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 37.9        |
|    ep_rew_mean          | 111         |
| time/                   |             |
|    fps                  | 768         |
|    iterations           | 10          |
|    time_elapsed         | 426         |
|    total_timesteps      | 327680      |
| train/                  |             |
|    approx_kl            | 0.051594026 |
|    clip_fraction        | 0.453       |
|    clip_range           | 0.2         |
|    entropy_loss         | -3          |
|    explained_variance   | 0.85        |
|    learning_rate        | 0.0003      |
|    loss                 | -0.0606     |
|    n_updates            | 90          |
|    policy_gradient_loss | -0.0555     |
|    value_loss           | 0.123       |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 37.7        |
|    ep_rew_mean          | 115         |
| time/                   |             |
|    fps                  | 758         |
|    iterations           | 11          |
|    time_elapsed         | 474         |
|    total_timesteps      | 360448      |
| train/                  |             |
|    approx_kl            | 0.054209635 |
|    clip_fraction        | 0.459       |
|    clip_range           | 0.2         |
|    entropy_loss         | -2.98       |
|    explained_variance   | 0.841       |
|    learning_rate        | 0.0003      |
|    loss                 | -0.0776     |
|    n_updates            | 100         |
|    policy_gradient_loss | -0.0564     |
|    value_loss           | 0.127       |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 37.9        |
|    ep_rew_mean          | 107         |
| time/                   |             |
|    fps                  | 755         |
|    iterations           | 12          |
|    time_elapsed         | 520         |
|    total_timesteps      | 393216      |
| train/                  |             |
|    approx_kl            | 0.053540003 |
|    clip_fraction        | 0.461       |
|    clip_range           | 0.2         |
|    entropy_loss         | -2.95       |
|    explained_variance   | 0.853       |
|    learning_rate        | 0.0003      |
|    loss                 | -0.0494     |
|    n_updates            | 110         |
|    policy_gradient_loss | -0.0571     |
|    value_loss           | 0.12        |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 37.9        |
|    ep_rew_mean          | 115         |
| time/                   |             |
|    fps                  | 753         |
|    iterations           | 13          |
|    time_elapsed         | 565         |
|    total_timesteps      | 425984      |
| train/                  |             |
|    approx_kl            | 0.053906888 |
|    clip_fraction        | 0.463       |
|    clip_range           | 0.2         |
|    entropy_loss         | -2.93       |
|    explained_variance   | 0.854       |
|    learning_rate        | 0.0003      |
|    loss                 | -0.0661     |
|    n_updates            | 120         |
|    policy_gradient_loss | -0.0571     |
|    value_loss           | 0.114       |
-----------------------------------------
INFO:train_ppo_vecnorm:Entrenando PPO Fase 3 por 300000 timesteps...
Using cpu device
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 38.3     |
|    ep_rew_mean     | 114      |
| time/              |          |
|    fps             | 2040     |
|    iterations      | 1        |
|    time_elapsed    | 24       |
|    total_timesteps | 49152    |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 37.9       |
|    ep_rew_mean          | 110        |
| time/                   |            |
|    fps                  | 1070       |
|    iterations           | 2          |
|    time_elapsed         | 91         |
|    total_timesteps      | 98304      |
| train/                  |            |
|    approx_kl            | 0.05399221 |
|    clip_fraction        | 0.462      |
|    clip_range           | 0.2        |
|    entropy_loss         | -2.88      |
|    explained_variance   | 0.848      |
|    learning_rate        | 0.0003     |
|    loss                 | -0.0429    |
|    n_updates            | 10         |
|    policy_gradient_loss | -0.0455    |
|    value_loss           | 0.125      |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 37.9        |
|    ep_rew_mean          | 111         |
| time/                   |             |
|    fps                  | 920         |
|    iterations           | 3           |
|    time_elapsed         | 160         |
|    total_timesteps      | 147456      |
| train/                  |             |
|    approx_kl            | 0.054461405 |
|    clip_fraction        | 0.461       |
|    clip_range           | 0.2         |
|    entropy_loss         | -2.85       |
|    explained_variance   | 0.856       |
|    learning_rate        | 0.0003      |
|    loss                 | -0.00742    |
|    n_updates            | 20          |
|    policy_gradient_loss | -0.0453     |
|    value_loss           | 0.119       |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 38.1        |
|    ep_rew_mean          | 113         |
| time/                   |             |
|    fps                  | 856         |
|    iterations           | 4           |
|    time_elapsed         | 229         |
|    total_timesteps      | 196608      |
| train/                  |             |
|    approx_kl            | 0.056124333 |
|    clip_fraction        | 0.464       |
|    clip_range           | 0.2         |
|    entropy_loss         | -2.82       |
|    explained_variance   | 0.85        |
|    learning_rate        | 0.0003      |
|    loss                 | -0.0466     |
|    n_updates            | 30          |
|    policy_gradient_loss | -0.0458     |
|    value_loss           | 0.127       |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 38          |
|    ep_rew_mean          | 114         |
| time/                   |             |
|    fps                  | 827         |
|    iterations           | 5           |
|    time_elapsed         | 297         |
|    total_timesteps      | 245760      |
| train/                  |             |
|    approx_kl            | 0.055779744 |
|    clip_fraction        | 0.465       |
|    clip_range           | 0.2         |
|    entropy_loss         | -2.77       |
|    explained_variance   | 0.854       |
|    learning_rate        | 0.0003      |
|    loss                 | -0.0333     |
|    n_updates            | 40          |
|    policy_gradient_loss | -0.0463     |
|    value_loss           | 0.126       |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 38.2       |
|    ep_rew_mean          | 118        |
| time/                   |            |
|    fps                  | 806        |
|    iterations           | 6          |
|    time_elapsed         | 365        |
|    total_timesteps      | 294912     |
| train/                  |            |
|    approx_kl            | 0.05700341 |
|    clip_fraction        | 0.465      |
|    clip_range           | 0.2        |
|    entropy_loss         | -2.74      |
|    explained_variance   | 0.854      |
|    learning_rate        | 0.0003     |
|    loss                 | -0.0461    |
|    n_updates            | 50         |
|    policy_gradient_loss | -0.0462    |
|    value_loss           | 0.124      |
----------------------------------------
--------------------------------------
| rollout/                |          |
|    ep_len_mean          | 37.9     |
|    ep_rew_mean          | 114      |
| time/                   |          |
|    fps                  | 792      |
|    iterations           | 7        |
|    time_elapsed         | 433      |
|    total_timesteps      | 344064   |
| train/                  |          |
|    approx_kl            | 0.058787 |
|    clip_fraction        | 0.47     |
|    clip_range           | 0.2      |
|    entropy_loss         | -2.71    |
|    explained_variance   | 0.858    |
|    learning_rate        | 0.0003   |
|    loss                 | -0.0207  |
|    n_updates            | 60       |
|    policy_gradient_loss | -0.0467  |
|    value_loss           | 0.12     |
--------------------------------------
INFO:train_ppo_vecnorm:Modelo guardado en best/ppo_ablation/ppo_baseline/seed_126/best/ppo_yahtzee_vecnorm_final y estadisticas de normalizacion en best/ppo_ablation/ppo_baseline/seed_126/best/ppo_vecnorm_stats.pkl
INFO:final_evaluate_rl:Autodeteccion: modelo=best/ppo_ablation/ppo_baseline/seed_126/best/ppo_yahtzee_vecnorm_final, stats=best/ppo_ablation/ppo_baseline/seed_126/best/ppo_vecnorm_stats.pkl, algo=ppo
INFO:final_evaluate_rl:Cargando modelo: best/ppo_ablation/ppo_baseline/seed_126/best/ppo_yahtzee_vecnorm_final
INFO:final_evaluate_rl:Algo detectado/forzado: ppo
INFO:final_evaluate_rl:Evaluando el modelo con recompensas SIN normalizar(evaluacion segura)...
INFO:final_evaluate_rl:Episode 1: Recompensa del episodio: 141.3245011898689, Puntuacion final: 143.0
INFO:final_evaluate_rl:Episode 2: Recompensa del episodio: 76.77150065242313, Puntuacion final: 78.0
INFO:final_evaluate_rl:Episode 3: Recompensa del episodio: 111.8470015223138, Puntuacion final: 115.0
INFO:final_evaluate_rl:Episode 4: Recompensa del episodio: 106.82749928766862, Puntuacion final: 111.0
INFO:final_evaluate_rl:Episode 5: Recompensa del episodio: 101.64599882625043, Puntuacion final: 104.0
INFO:final_evaluate_rl:Episode 6: Recompensa del episodio: 102.34449868043885, Puntuacion final: 105.0
INFO:final_evaluate_rl:Episode 7: Recompensa del episodio: 172.76200133096427, Puntuacion final: 176.0
INFO:final_evaluate_rl:Episode 8: Recompensa del episodio: 100.53199951117858, Puntuacion final: 102.0
INFO:final_evaluate_rl:Episode 9: Recompensa del episodio: 156.84000089205801, Puntuacion final: 159.0
INFO:final_evaluate_rl:Episode 10: Recompensa del episodio: 169.79400144406827, Puntuacion final: 172.0
INFO:final_evaluate_rl:Episode 11: Recompensa del episodio: 127.80350075685419, Puntuacion final: 129.0
INFO:final_evaluate_rl:Episode 12: Recompensa del episodio: 83.72500062186737, Puntuacion final: 86.0
INFO:final_evaluate_rl:Episode 13: Recompensa del episodio: 116.90700027998537, Puntuacion final: 119.0
INFO:final_evaluate_rl:Episode 14: Recompensa del episodio: 170.99850241397507, Puntuacion final: 173.0
INFO:final_evaluate_rl:Episode 15: Recompensa del episodio: 128.1539997693617, Puntuacion final: 130.0
INFO:final_evaluate_rl:Episode 16: Recompensa del episodio: 150.8414993933984, Puntuacion final: 152.0
INFO:final_evaluate_rl:Episode 17: Recompensa del episodio: 126.60899922490353, Puntuacion final: 129.0
INFO:final_evaluate_rl:Episode 18: Recompensa del episodio: 147.68399916030467, Puntuacion final: 150.0
INFO:final_evaluate_rl:Episode 19: Recompensa del episodio: 120.15799958258867, Puntuacion final: 122.0
INFO:final_evaluate_rl:Episode 20: Recompensa del episodio: 115.23349821474403, Puntuacion final: 117.0
INFO:final_evaluate_rl:Episode 21: Recompensa del episodio: 81.99549997388385, Puntuacion final: 84.0
INFO:final_evaluate_rl:Episode 22: Recompensa del episodio: 118.97899893537397, Puntuacion final: 121.0
INFO:final_evaluate_rl:Episode 23: Recompensa del episodio: 165.13199665560387, Puntuacion final: 167.0
INFO:final_evaluate_rl:Episode 24: Recompensa del episodio: 99.12500026647467, Puntuacion final: 101.0
INFO:final_evaluate_rl:Episode 25: Recompensa del episodio: 162.79449706873856, Puntuacion final: 166.0
INFO:final_evaluate_rl:Episode 26: Recompensa del episodio: 85.51349938288331, Puntuacion final: 87.0
INFO:final_evaluate_rl:Episode 27: Recompensa del episodio: 72.43900009198114, Puntuacion final: 75.0
INFO:final_evaluate_rl:Episode 28: Recompensa del episodio: 133.63100229296833, Puntuacion final: 135.0
INFO:final_evaluate_rl:Episode 29: Recompensa del episodio: 146.69500210206024, Puntuacion final: 149.0
INFO:final_evaluate_rl:Episode 30: Recompensa del episodio: 127.76599867839832, Puntuacion final: 130.0
INFO:final_evaluate_rl:Episode 31: Recompensa del episodio: 113.11899839370744, Puntuacion final: 115.0
INFO:final_evaluate_rl:Episode 32: Recompensa del episodio: 149.61049999354873, Puntuacion final: 152.0
INFO:final_evaluate_rl:Episode 33: Recompensa del episodio: 190.27850223245332, Puntuacion final: 192.0
INFO:final_evaluate_rl:Episode 34: Recompensa del episodio: 80.43049908371177, Puntuacion final: 83.0
INFO:final_evaluate_rl:Episode 35: Recompensa del episodio: 133.91200028778985, Puntuacion final: 136.0
INFO:final_evaluate_rl:Episode 36: Recompensa del episodio: 106.87249873252586, Puntuacion final: 110.0
INFO:final_evaluate_rl:Episode 37: Recompensa del episodio: 130.51150148618035, Puntuacion final: 133.0
INFO:final_evaluate_rl:Episode 38: Recompensa del episodio: 98.840497780242, Puntuacion final: 102.0
INFO:final_evaluate_rl:Episode 39: Recompensa del episodio: 139.86350186844356, Puntuacion final: 144.0
INFO:final_evaluate_rl:Episode 40: Recompensa del episodio: 150.05399912665598, Puntuacion final: 152.0
INFO:final_evaluate_rl:Episode 41: Recompensa del episodio: 144.82349909376353, Puntuacion final: 147.0
INFO:final_evaluate_rl:Episode 42: Recompensa del episodio: 144.32599789951928, Puntuacion final: 146.0
INFO:final_evaluate_rl:Episode 43: Recompensa del episodio: 94.84300086041912, Puntuacion final: 97.0
INFO:final_evaluate_rl:Episode 44: Recompensa del episodio: 111.78099926607683, Puntuacion final: 115.0
INFO:final_evaluate_rl:Episode 45: Recompensa del episodio: 107.23449890338816, Puntuacion final: 109.0
INFO:final_evaluate_rl:Episode 46: Recompensa del episodio: 132.81649914802983, Puntuacion final: 136.0
INFO:final_evaluate_rl:Episode 47: Recompensa del episodio: 129.73449916683603, Puntuacion final: 132.0
INFO:final_evaluate_rl:Episode 48: Recompensa del episodio: 124.22900081076659, Puntuacion final: 126.0
INFO:final_evaluate_rl:Episode 49: Recompensa del episodio: 122.68100170837715, Puntuacion final: 125.0
INFO:final_evaluate_rl:Episode 50: Recompensa del episodio: 117.13350044563413, Puntuacion final: 119.0
INFO:final_evaluate_rl:Metricas guardadas en ppo_vecnorm_final_evaluation_metrics.txt
Grafica guardada en best/ppo_ablation/ppo_baseline/seed_126/best/ppo_vecnorm_reward_evolution.png

Resumen:
  Recompensa media (sin normalizar): 124.9194
  Puntuacion final promedio:        127.1600
